{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, cyclic_encode_fn, log_transform\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "import time\n",
    "\n",
    "class ConvFullyBase(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 hidden_dim: int, \n",
    "                 output_dim: int,\n",
    "                 group_size: int):\n",
    "        super(ConvFullyBase, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.group_size = group_size\n",
    "\n",
    "        self.pos_emb = nn.Embedding(self.group_size*3, 2)\n",
    "        # Task 1 layers\n",
    "        self.fc1= nn.Conv1d(in_channels=(self.input_dim+2)*self.group_size,\n",
    "                            out_channels=self.hidden_dim*group_size,\n",
    "                            kernel_size=1,\n",
    "                            stride=1,\n",
    "                            groups=self.group_size)\n",
    "        # Final MLP layer\n",
    "        self.fc_final= nn.Conv1d(in_channels=self.hidden_dim*self.group_size,\n",
    "                            out_channels=self.output_dim*group_size,\n",
    "                            kernel_size=1,\n",
    "                            stride=1,\n",
    "                            groups=self.group_size)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, x_cate: torch.Tensor):\n",
    "        torch.cuda.synchronize()  # 동기화 시작\n",
    "        start_time = time.time()\n",
    "        \n",
    "        x_cate = self.pos_emb(x_cate)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"embedding runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        x = torch.concat([x, x_cate], dim=-1)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"concat runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        if x.ndim == 2:\n",
    "            x = x.unsqueeze(dim=0)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"if runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        x_shape = x.shape\n",
    "        B = x_shape[0]\n",
    "        x = x.reshape(B, -1, 1)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"reshape runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        x1 = self.fc1(x)\n",
    "        x1 = self.relu(x1)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"fc1 runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        out = self.fc_final(x1)\n",
    "        out = out.reshape(B, x_shape[1], -1)\n",
    "        torch.cuda.synchronize()\n",
    "        print(f\"last runtime: {time.time() - start_time:.4f} seconds\")\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class BaseLSTMModel(nn.Module):\n",
    "    def __init__(self, small_input_dim, large_input_dim, hidden_dim, output_dim, num_layers=2):\n",
    "        super(BaseLSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.small_lstm = nn.LSTM(small_input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.large_lstm = nn.LSTM(large_input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        # self.lstm = LSTM(input_dim, hidden_dim, num_layers)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "    \n",
    "    def forward(self, small_x, large_x):\n",
    "        h0 = torch.zeros(self.num_layers, small_x.size(0), self.hidden_dim).to(small_x.device)\n",
    "        c0 = torch.zeros(self.num_layers, small_x.size(0), self.hidden_dim).to(small_x.device)\n",
    "        small_out, _ = self.small_lstm(small_x, (h0, c0))\n",
    "        small_out = small_out[:, -1, :]\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, large_x.size(0), self.hidden_dim).to(large_x.device)\n",
    "        c0 = torch.zeros(self.num_layers, large_x.size(0), self.hidden_dim).to(large_x.device)\n",
    "        large_out, _ = self.large_lstm(large_x, (h0, c0))\n",
    "        large_out = large_out[:, -1, :]\n",
    "        \n",
    "        out = torch.concat([small_out, large_out], dim=-1)\n",
    "        \n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out)\n",
    "        return out.cpu().unsqueeze(dim=1)\n",
    "\n",
    "class Prescriptor(nn.Module):\n",
    "    def __init__(self, \n",
    "                 basic_block: nn.Module, \n",
    "                 base_small_input_dim: int, \n",
    "                 base_large_input_dim: int,\n",
    "                 base_hidden_dim: int, \n",
    "                 base_output_dim: int,\n",
    "                 after_input_dim: int,\n",
    "                 after_hidden_dim: int,\n",
    "                 after_output_dim: int, \n",
    "                 num_blocks: int = 1):\n",
    "        super(Prescriptor, self).__init__()\n",
    "        \n",
    "        if basic_block == None:\n",
    "            self.base_network = BaseLSTMModel\n",
    "        else:\n",
    "            self.base_network = basic_block\n",
    "            \n",
    "        self.layers = nn.ModuleList([self.base_network(base_small_input_dim, base_large_input_dim, base_hidden_dim, base_output_dim) for _ in range(num_blocks)])\n",
    "        self.after_layers = ConvFullyBase(after_input_dim, after_hidden_dim, after_output_dim, group_size=num_blocks)\n",
    "        self.num_blcoks = num_blocks\n",
    "        \n",
    "        \n",
    "    def forward(self, small_x, large_x):\n",
    "        outputs = [layer(small_x, large_x) for layer in self.layers]\n",
    "        # outputs = torch.concat(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def base_forward(self, small_x, large_x):\n",
    "        outputs = [layer(small_x, large_x) for layer in self.layers]\n",
    "        # outputs = torch.concat(outputs)\n",
    "        return outputs\n",
    "    \n",
    "    def after_forward(self, x, x_cate):\n",
    "        return self.after_layers(x, x_cate)\n",
    "    \n",
    "\n",
    "class ChromosomeSelectorModel(nn.Module):\n",
    "    def __init__(self, small_input_dim, large_input_dim, hidden_dim, num_chromosomes, num_layers=2):\n",
    "        super(ChromosomeSelectorModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the LSTM layers\n",
    "        self.small_lstm = nn.LSTM(small_input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.large_lstm = nn.LSTM(large_input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the output layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_chromosomes)\n",
    "    \n",
    "    def forward(self, small_x, large_x):\n",
    "        h0_small = torch.zeros(self.num_layers, small_x.size(0), self.hidden_dim).to(small_x.device)\n",
    "        c0_small = torch.zeros(self.num_layers, small_x.size(0), self.hidden_dim).to(small_x.device)\n",
    "        small_out, _ = self.small_lstm(small_x, (h0_small, c0_small))\n",
    "        small_out = small_out[:, -1, :]\n",
    "\n",
    "        h0_large = torch.zeros(self.num_layers, large_x.size(0), self.hidden_dim).to(large_x.device)\n",
    "        c0_large = torch.zeros(self.num_layers, large_x.size(0), self.hidden_dim).to(large_x.device)\n",
    "        large_out, _ = self.large_lstm(large_x, (h0_large, c0_large))\n",
    "        large_out = large_out[:, -1, :]\n",
    "        \n",
    "        # Concatenate outputs\n",
    "        combined_out = torch.cat([small_out, large_out], dim=-1)\n",
    "        \n",
    "        # Output scores for each chromosome\n",
    "        scores = self.fc(combined_out)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_1m = load_data_1m('/root/daily/bit/data/1min_bitusdt.pkl')\n",
    "data_1m = data_1m.iloc[:200000]\n",
    "\n",
    "# Resample data to 1D\n",
    "data_1d = resample_data(data_1m, '1D')\n",
    "data_1d['Close time'] = data_1d.index\n",
    "data_1d = data_1d.reset_index(drop=True)\n",
    "\n",
    "# Apply Feature Calculations\n",
    "# For 1D Data\n",
    "data_1d, ma_cols_1d, ma_cols_rel_1d = calculate_MA_data(data_1d, 60, 'EMA', '_1d')\n",
    "data_1d, bb_cols_1d, bb_cols_rel_1d = calculate_ema_bollinger_bands(data_1d, 60, extra_str='_1d')\n",
    "data_1d, rsi_cols_1d = calculate_rsi(data_1d, window=20, extra_str='_1d')\n",
    "data_1d, macd_cols_1d = calculate_macd(data_1d, 20, 120, 60, extra_str='_1d')\n",
    "data_1d, stoch_cols_1d = calculate_stochastic_oscillator(data_1d, 60, 20, extra_str='_1d')\n",
    "data_1d, adx_cols_1d = calculate_adx(data_1d, 60, extra_str='_1d')\n",
    "data_1d, atr_cols_1d = calculate_atr(data_1d, 60, extra_str='_1d')\n",
    "data_1d, obv_cols_1d = calculate_obv(data_1d, extra_str='_1d')\n",
    "data_1d, will_cols_1d = calculate_williams_r(data_1d, 60, extra_str='_1d')\n",
    "data_1d, base_feature_1d = base_feature_fn(data_1d, extra_str='_1d')\n",
    "data_1d, cyclice_encoding_1d = cyclic_encode_fn(data_1d, 'Close time', 'day_of_year')\n",
    "\n",
    "# For 1M Data\n",
    "data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, 240, 'EMA')\n",
    "data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, 240)\n",
    "data_1m, rsi_cols = calculate_rsi(data_1m, window=60)\n",
    "data_1m, macd_cols = calculate_macd(data_1m, 60, 600, 240)\n",
    "data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, 240, 60)\n",
    "data_1m, adx_cols = calculate_adx(data_1m, 240)\n",
    "data_1m, atr_cols = calculate_atr(data_1m, 240)\n",
    "data_1m, obv_cols = calculate_obv(data_1m)\n",
    "data_1m, will_cols = calculate_williams_r(data_1m, 240)\n",
    "data_1m, base_feature = base_feature_fn(data_1m)\n",
    "data_1m, cyclice_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "data_1m, short_ma_cols, short_ma_cols_rel = calculate_MA_data(data_1m, 60, 'EMA')\n",
    "data_1m, long_ma_cols, long_ma_cols_rel = calculate_MA_data(data_1m, 180, 'EMA')\n",
    "\n",
    "# Prepare Feature Columns\n",
    "drop_column = [\n",
    "    'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "    'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "]\n",
    "feature_column = (\n",
    "    ma_cols_rel + bb_cols_rel + rsi_cols + macd_cols + stoch_cols +\n",
    "    adx_cols + will_cols + base_feature + cyclice_encoding  # Excluding obv and atr\n",
    ")\n",
    "feature_column_1d = (\n",
    "    ma_cols_rel_1d + bb_cols_rel_1d + rsi_cols_1d + macd_cols_1d + stoch_cols_1d +\n",
    "    adx_cols_1d + will_cols_1d + base_feature_1d + cyclice_encoding_1d\n",
    ")\n",
    "\n",
    "\n",
    "# Apply Log Transform\n",
    "for feature in feature_column:\n",
    "    data_1m[feature] = log_transform(data_1m[feature])\n",
    "\n",
    "for feature in feature_column_1d:\n",
    "    data_1d[feature] = log_transform(data_1d[feature])\n",
    "\n",
    "data_1d['%D_20__1d'] = 0\n",
    "data_1d['ADX_60__1d'] = 0\n",
    "\n",
    "\n",
    "# bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 240, 60, 180)\n",
    "\n",
    "# Prepare Dataset\n",
    "data_tensor = make_dataset(\n",
    "    data_1m, data_1d,\n",
    "    using_column=feature_column, using_column_1d=feature_column_1d,\n",
    "    window_size=240, window_size_1d=60,\n",
    "    entry_pos_list=bb_macd_entry_pos_list, patience_list=patience_list,\n",
    "    use_1d_data=True\n",
    ")\n",
    "entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "dataset_1m = []\n",
    "dataset_1d = []\n",
    "skip_data_cnt = 0\n",
    "for data in data_tensor:\n",
    "    if len(data[0]) == 240 and len(data[1]) == 60:\n",
    "        dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    "        dataset_1d.append(torch.from_numpy(data[1]).unsqueeze(dim=0))\n",
    "    else:\n",
    "        skip_data_cnt += 1\n",
    "dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "dataset_1d = torch.cat(dataset_1d, dim=0)\n",
    "dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "dataset_1d = replace_nan_with_zero(dataset_1d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolution Setup\n",
    "\n",
    "# 전역적으로 기울기 계산 비활성화\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "device = 'cuda:0'\n",
    "group = 10000\n",
    "prescriptor = Prescriptor(\n",
    "    basic_block=None, \n",
    "    base_small_input_dim=19, \n",
    "    base_large_input_dim=19,\n",
    "    base_hidden_dim=24, \n",
    "    base_output_dim=16, \n",
    "    after_input_dim=19, \n",
    "    after_hidden_dim=32, \n",
    "    after_output_dim=6, \n",
    "    num_blocks=group,\n",
    "    # nhead=4,\n",
    "    # dim_feedforward=24*4,\n",
    "    # dropout=0.1,\n",
    "    # small_max_seq_length=240,\n",
    "    # large_max_seq_length=60\n",
    ").to(device).eval()\n",
    "\n",
    "total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "selection = RouletteSelection(elite_num=2000, parents_num=4000, minimize=False)\n",
    "# selection = ParetoLexsortSelection(elite_num=2000, parents_num=4000,\n",
    "#                                     priority=[], prior_ratio= [],\n",
    "#                                     prob_method= 'softmax',minimize=False)\n",
    "crossover = DifferentialEvolutionOperator()\n",
    "mutation = RandomValueMutation(mut_prob=0.1)\n",
    "evolution = Evolution(\n",
    "    prescriptor=prescriptor,\n",
    "    selection=selection,\n",
    "    crossover=crossover,\n",
    "    mutation=mutation\n",
    ")\n",
    "\n",
    "start_gen = 0\n",
    "best_profit = None\n",
    "best_chromosomes = None\n",
    "\n",
    "# state_dict_path = '/root/daily/bit/generation/generation_2_backup.pt'\n",
    "# if os.path.exists(state_dict_path):\n",
    "#     print('load_state')\n",
    "#     state_dict = torch.load(state_dict_path)\n",
    "#     start_gen = state_dict['generation'] + 1\n",
    "#     best_profit = state_dict['best_profit']\n",
    "#     best_chromosomes = state_dict['best_chromosomes']\n",
    "#     prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "# start_gen = 0\n",
    "\n",
    "# # best_profit = None\n",
    "# # best_chromosomes = None\n",
    "\n",
    "# init_chromosomes, base_ch_shape, after_ch_shape, device = evolution.flatten_chromosomes()\n",
    "# best_chromosomes = best_chromosomes[4485].unsqueeze(dim=0)\n",
    "# device = 'cuda:0'\n",
    "# evolution.update_chromosomes(best_chromosomes, base_ch_shape, after_ch_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_skip_data_cnt = int(len(dataset_1m)*0.6) + skip_data_cnt\n",
    "test_skip_data_cnt = int(len(dataset_1m)*0.8) + skip_data_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "from strategies import BBStrategy\n",
    "from icecream import ic\n",
    "from copy import deepcopy\n",
    "\n",
    "def days_difference(date1, date2):\n",
    "    # 날짜 차이 계산\n",
    "    difference = date2 - date1\n",
    "    # 일수 반환\n",
    "    return np.abs(difference / np.timedelta64(1, 'D')).astype(int)\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def calculate_performance_metrics(returns_list, minimum_date=40):\n",
    "    \"\"\"\n",
    "    Calculate performance metrics for each chromosome based on their returns.\n",
    "\n",
    "    Args:\n",
    "        returns_list (np.ndarray): An array of shape (chromosomes_size, time_steps) containing the returns.\n",
    "        minimum_date (int): Minimum number of non-zero returns required to calculate metrics.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array containing performance metrics for each chromosome.\n",
    "    \"\"\"\n",
    "    chromosomes_size = returns_list.shape[0]\n",
    "\n",
    "    # Initialize arrays to store performance metrics\n",
    "    mean_returns = np.full(chromosomes_size, -1e9)\n",
    "    sharpe_ratios = np.full(chromosomes_size, -1e9)\n",
    "    sortino_ratios = np.full(chromosomes_size, -1e9)\n",
    "    profit_factors = np.full(chromosomes_size, -1e9)\n",
    "    win_rates = np.full(chromosomes_size, -1e9)\n",
    "    max_drawdowns = np.full(chromosomes_size, 1e9)\n",
    "    cumulative_returns = np.full(chromosomes_size, -1e9)  # Initialize Cumulative Returns\n",
    "\n",
    "    risk_free_rate = 0.0  # Adjust as needed\n",
    "\n",
    "    # Compute the number of non-zero returns for each chromosome\n",
    "    num_non_zero = np.count_nonzero(returns_list != 0, axis=1)\n",
    "    valid_chromosomes = num_non_zero > (minimum_date // 3)\n",
    "\n",
    "    if sum(valid_chromosomes) != 0:\n",
    "        # Replace zeros with NaN for non-zero returns calculations\n",
    "        non_zero_returns_list = np.where(returns_list != 0, returns_list, np.nan)\n",
    "\n",
    "        # Compute mean returns and standard deviations\n",
    "        mean_returns[valid_chromosomes] = np.nanmean(non_zero_returns_list[valid_chromosomes], axis=1)\n",
    "        std_returns_i = np.nanstd(non_zero_returns_list[valid_chromosomes], axis=1) + 1e-9\n",
    "\n",
    "        # Sharpe Ratios\n",
    "        valid_std = (std_returns_i != 0) & (~np.isnan(std_returns_i))\n",
    "        sharpe_ratios_subset = (mean_returns[valid_chromosomes] - risk_free_rate) / std_returns_i\n",
    "        sharpe_ratios[valid_chromosomes] = np.where(valid_std, sharpe_ratios_subset, -1e9)\n",
    "        sharpe_ratios = np.where(np.isnan(sharpe_ratios), -1e9, sharpe_ratios)\n",
    "\n",
    "        # Max Drawdown\n",
    "        cumulative_returns_raw = np.cumsum(returns_list, axis=1)\n",
    "        running_max = np.maximum.accumulate(cumulative_returns_raw, axis=1)\n",
    "        drawdowns = running_max - cumulative_returns_raw\n",
    "        max_drawdowns[valid_chromosomes] = np.nanmax(drawdowns[valid_chromosomes], axis=1)\n",
    "\n",
    "        # Sortino Ratios\n",
    "        negative_returns = np.where(non_zero_returns_list < 0, non_zero_returns_list, np.nan)\n",
    "        downside_std = np.nanstd(negative_returns[valid_chromosomes], axis=1) + 1e-9\n",
    "        valid_downside_std = (downside_std != 0) & (~np.isnan(downside_std))\n",
    "        sortino_ratios_subset = (mean_returns[valid_chromosomes] - risk_free_rate) / downside_std\n",
    "        sortino_ratios[valid_chromosomes] = np.where(valid_downside_std, sortino_ratios_subset, -1e9)\n",
    "        sortino_ratios = np.where(np.isnan(sortino_ratios), -1e9, sortino_ratios)\n",
    "\n",
    "        # Profit Factor\n",
    "        total_profit = np.nansum(np.where(non_zero_returns_list > 0, non_zero_returns_list, 0), axis=1)\n",
    "        total_loss = -np.nansum(np.where(non_zero_returns_list < 0, non_zero_returns_list, 0), axis=1)\n",
    "        valid_total_loss = (total_loss != 0) & (~np.isnan(total_loss))\n",
    "        profit_factors[valid_chromosomes] = -1e9\n",
    "        profit_factors[valid_chromosomes & valid_total_loss] = total_profit[valid_chromosomes & valid_total_loss] / (total_loss[valid_chromosomes & valid_total_loss] + 1e-9)\n",
    "        profit_factors = np.where(np.isnan(profit_factors), -1e9, profit_factors)\n",
    "\n",
    "        # Win Rate\n",
    "        num_wins = np.nansum(np.where(non_zero_returns_list > 0, 1, 0), axis=1)\n",
    "        num_trades = num_non_zero\n",
    "        valid_num_trades = (num_trades != 0) & (~np.isnan(num_trades))\n",
    "        win_rates[valid_chromosomes] = -1e9\n",
    "        win_rates[valid_chromosomes & valid_num_trades] = num_wins[valid_chromosomes & valid_num_trades] / num_trades[valid_chromosomes & valid_num_trades]\n",
    "        win_rates = np.where(np.isnan(win_rates), -1e9, win_rates)\n",
    "\n",
    "        # Calculate Cumulative Returns\n",
    "        initial_value = 1.0\n",
    "        for idx in np.where(valid_chromosomes)[0]:\n",
    "            clean_returns = returns_list[idx][returns_list[idx] != 0]\n",
    "            current_value = initial_value\n",
    "            for ret in clean_returns:\n",
    "                current_value += current_value * (ret / 100.0)\n",
    "            cumulative_returns[idx] = current_value\n",
    "\n",
    "    high_drawdown_indices = max_drawdowns >= 60\n",
    "    mean_returns[high_drawdown_indices] /= 2\n",
    "    sharpe_ratios[high_drawdown_indices] /= 2\n",
    "    sortino_ratios[high_drawdown_indices] /= 2\n",
    "    profit_factors[high_drawdown_indices] /= 2\n",
    "    win_rates[high_drawdown_indices] /= 2\n",
    "    cumulative_returns[high_drawdown_indices] /= 2\n",
    "\n",
    "    # Expand dimensions and concatenate\n",
    "    metrics = np.concatenate([\n",
    "        np.expand_dims(mean_returns, axis=1),\n",
    "        np.expand_dims(sharpe_ratios, axis=1),\n",
    "        np.expand_dims(sortino_ratios, axis=1),\n",
    "        np.expand_dims(profit_factors, axis=1),\n",
    "        np.expand_dims(win_rates, axis=1),\n",
    "        np.expand_dims(max_drawdowns, axis=1),\n",
    "        np.expand_dims(cumulative_returns, axis=1)  # Add Cumulative Returns\n",
    "    ], axis=1)\n",
    "\n",
    "    # print(metrics[np.where(high_drawdown_indices)[0]])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, data_1d):\n",
    "        self.data = data\n",
    "        self.data_1d = data_1d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data_1d[idx]\n",
    "\n",
    "def inference(scaled_tensor, scaled_tensor_1d, model, device='cuda:0'):\n",
    "    dataset = CustomDataset(scaled_tensor, scaled_tensor_1d)\n",
    "    dataloader = DataLoader(dataset, batch_size=512, shuffle=False, num_workers=4)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    logits = []\n",
    "    with torch.no_grad():\n",
    "        for data, data_1d in dataloader:\n",
    "            data = data.to(torch.float32).to(device)\n",
    "            data_1d = data_1d.to(torch.float32).to(device)\n",
    "            logit = model.base_forward(data, data_1d)\n",
    "            logits.append(logit)\n",
    "    return logits\n",
    "\n",
    "def loss_cut_fn(pos_list, price_list, leverage_ratio, enter_ratio, profit, curr_low, curr_high, additional_count, alpha=1., cut_percent=80.):\n",
    "\n",
    "    # Positions: 'short' -> 1, 'long' -> 2, 'hold' -> 0\n",
    "    short_index = torch.where(pos_list == 1)[0]\n",
    "    long_index = torch.where(pos_list == 2)[0]\n",
    "\n",
    "    # Calculate profit or loss\n",
    "    short_profit = -((curr_high - price_list[short_index]) / price_list[short_index] * 100.) * leverage_ratio[short_index]\n",
    "    long_profit = ((curr_low - price_list[long_index]) / price_list[long_index] * 100.) * leverage_ratio[long_index]\n",
    "    \n",
    "    # Determine positions to cut\n",
    "    short_cut_index = torch.where(short_profit <= -cut_percent)[0]\n",
    "    long_cut_index = torch.where(long_profit <= -cut_percent)[0]\n",
    "\n",
    "    # Update state for short positions to be cut\n",
    "    short_index = short_index[short_cut_index]\n",
    "    profit[short_index] = profit[short_index] - (enter_ratio[short_index] * cut_percent * alpha) - 0.1 * leverage_ratio[short_index] * enter_ratio[short_index]\n",
    "    pos_list[short_index] = 0\n",
    "    price_list[short_index] = -1.\n",
    "    leverage_ratio[short_index] = -1\n",
    "    enter_ratio[short_index] = -1.\n",
    "    additional_count[short_index] = 0\n",
    "\n",
    "    # Update state for long positions to be cut\n",
    "    long_index = long_index[long_cut_index]\n",
    "    profit[long_index] = profit[long_index] - (enter_ratio[long_index] * cut_percent * alpha) - 0.1 * leverage_ratio[long_index] * enter_ratio[long_index]\n",
    "    pos_list[long_index] = 0\n",
    "    price_list[long_index] = -1.\n",
    "    leverage_ratio[long_index] = -1\n",
    "    enter_ratio[long_index] = -1.\n",
    "    additional_count[long_index] = 0\n",
    "\n",
    "    \n",
    "    return pos_list, price_list, leverage_ratio, enter_ratio, additional_count, profit\n",
    "\n",
    "\n",
    "def calculate_same(same_prob, pos_list, price_list, leverage_ratio, enter_ratio, profit, entry_pos, curr_close, additional_count, limit=2, cut_value=1.):\n",
    "    index = torch.tensor([0, 1, 3])\n",
    "    logit = torch.argmax(same_prob[:, index], dim=1)\n",
    "    hold_index = torch.where(logit == 0)[0]\n",
    "    enter_index = torch.where((logit == 1) & (additional_count < limit))[0]\n",
    "    loss_index = torch.where(logit == 2)[0]\n",
    "\n",
    "    # loss\n",
    "    pos_list[loss_index] = 0  # 'hold' -> 0\n",
    "    loss_profit = (price_list[loss_index] - curr_close) / price_list[loss_index] * 100\n",
    "    loss_profit = loss_profit * leverage_ratio[loss_index] * enter_ratio[loss_index]\n",
    "\n",
    "    # enter\n",
    "    before_price_list = price_list[enter_index]\n",
    "    before_enter_list = enter_ratio[enter_index]\n",
    "    cut_enter = cut_value - before_enter_list\n",
    "    \n",
    "    enter_enter_ratio = torch.sigmoid(same_prob[enter_index][:, 5])\n",
    "    enter_enter_ratio = torch.minimum(cut_enter, enter_enter_ratio)\n",
    "    after_price_list = before_price_list * (before_enter_list / (before_enter_list + enter_enter_ratio)) \\\n",
    "                       + curr_close * (enter_enter_ratio / (before_enter_list + enter_enter_ratio))\n",
    "    after_enter_ratio = before_enter_list + enter_enter_ratio\n",
    "\n",
    "    if entry_pos == 2:  # 'long' -> 2\n",
    "        profit[loss_index] = profit[loss_index] - loss_profit - 0.1 * leverage_ratio[loss_index] * enter_ratio[loss_index]\n",
    "    elif entry_pos == 1:  # 'short' -> 1\n",
    "        profit[loss_index] = profit[loss_index] + loss_profit - 0.1 * leverage_ratio[loss_index] * enter_ratio[loss_index]\n",
    "\n",
    "    price_list[loss_index] = -1.\n",
    "    leverage_ratio[loss_index] = -1\n",
    "    enter_ratio[loss_index] = -1.\n",
    "\n",
    "    # Increment additional_count for allowed entries\n",
    "    additional_count[enter_index] += 1\n",
    "    price_list[enter_index] = after_price_list\n",
    "    enter_ratio[enter_index] = after_enter_ratio\n",
    "\n",
    "    return pos_list, price_list, leverage_ratio, enter_ratio, additional_count, profit\n",
    "\n",
    "def calculate_diff(diff_prob, pos_list, price_list, leverage_ratio, enter_ratio, profit, entry_pos, curr_close, additional_count):\n",
    "    index = torch.tensor([0, 1, 2])\n",
    "    logit = torch.argmax(diff_prob[:, index], dim=1)\n",
    "    hold_index = torch.where(logit == 0)[0]\n",
    "    switch_index = torch.where(logit == 1)[0]\n",
    "    take_index = torch.where(logit == 2)[0]\n",
    "\n",
    "    # switch\n",
    "    switch_profit = (price_list[switch_index] - curr_close) / price_list[switch_index] * 100\n",
    "    switch_profit = switch_profit * leverage_ratio[switch_index] * enter_ratio[switch_index]\n",
    "    switch_leverage = torch.sigmoid(diff_prob[switch_index][:, 4]) * 100.\n",
    "    switch_enter_ratio = torch.sigmoid(diff_prob[switch_index][:, 5])\n",
    "\n",
    "    # take\n",
    "    pos_list[take_index] = 0  # 'hold' -> 0\n",
    "    take_profit = (price_list[take_index] - curr_close) / price_list[take_index] * 100\n",
    "    take_profit = take_profit * leverage_ratio[take_index] * enter_ratio[take_index]\n",
    "\n",
    "    if entry_pos == 2:  # 'long' -> 2\n",
    "        # switch\n",
    "        profit[switch_index] = profit[switch_index] + switch_profit - leverage_ratio[switch_index] * 0.1 * enter_ratio[switch_index]\n",
    "        pos_list[switch_index] = 2  # 'long' -> 2\n",
    "\n",
    "        # take\n",
    "        profit[take_index] = profit[take_index] + take_profit - leverage_ratio[take_index] * 0.1 * enter_ratio[take_index]\n",
    "    elif entry_pos == 1:  # 'short' -> 1\n",
    "        # switch\n",
    "        profit[switch_index] = profit[switch_index] - switch_profit - leverage_ratio[switch_index] * 0.1 * enter_ratio[switch_index]\n",
    "        pos_list[switch_index] = 1  # 'short' -> 1\n",
    "\n",
    "        # take\n",
    "        profit[take_index] = profit[take_index] - take_profit - leverage_ratio[take_index] * 0.1 * enter_ratio[take_index]\n",
    "\n",
    "    price_list[switch_index] = curr_close\n",
    "    leverage_ratio[switch_index] = switch_leverage.int()+1\n",
    "    enter_ratio[switch_index] = switch_enter_ratio\n",
    "\n",
    "    price_list[take_index] = -1.\n",
    "    leverage_ratio[take_index] = -1\n",
    "    enter_ratio[take_index] = -1.\n",
    "\n",
    "    # Reset additional_count for switched and taken positions\n",
    "    additional_count[switch_index] = 0\n",
    "    additional_count[take_index] = 0\n",
    "    return pos_list, price_list, leverage_ratio, enter_ratio, additional_count, profit\n",
    "\n",
    "\n",
    "def calculate_hold(hold_prob, pos_list, price_list, leverage_ratio, enter_ratio, profit, entry_pos, curr_close, additional_count):\n",
    "    index = torch.tensor([0, 1])\n",
    "    logit = torch.argmax(hold_prob[:, index], dim=1)\n",
    "    hold_index = torch.where(logit == 0)[0]\n",
    "    enter_index = torch.where(logit == 1)[0]\n",
    "\n",
    "    # enter\n",
    "    enter_leverage = torch.sigmoid(hold_prob[enter_index][:, 4]) * 100.\n",
    "    enter_enter_ratio = torch.sigmoid(hold_prob[enter_index][:, 5])\n",
    "    price_list[enter_index] = curr_close\n",
    "    leverage_ratio[enter_index] = enter_leverage.int() + 1\n",
    "    enter_ratio[enter_index] = enter_enter_ratio\n",
    "\n",
    "    if entry_pos == 2:  # 'long' -> 2\n",
    "        pos_list[enter_index] = 2  # 'long' -> 2\n",
    "    elif entry_pos == 1:  # 'short' -> 1\n",
    "        pos_list[enter_index] = 1  # 'short' -> 1\n",
    "\n",
    "    # Initialize additional_count for new positions\n",
    "    additional_count[enter_index] = 0\n",
    "\n",
    "    return pos_list, price_list, leverage_ratio, enter_ratio, additional_count, profit\n",
    "\n",
    "def calculate_now_profit(pos_list, price_list, leverage_ratio, enter_ratio, curr_price):\n",
    "    now_profit = torch.zeros_like(pos_list, dtype=torch.float32)\n",
    "    short_index = torch.where(pos_list == 1)[0]  # 'short' -> 1\n",
    "    long_index = torch.where(pos_list == 2)[0]  # 'long' -> 2\n",
    "\n",
    "    short_profit = (-((curr_price - price_list[short_index]) / price_list[short_index] * 100.) * leverage_ratio[short_index]) - 0.1 * leverage_ratio[short_index] * enter_ratio[short_index]\n",
    "    long_profit = (((curr_price - price_list[long_index]) / price_list[long_index] * 100.) * leverage_ratio[long_index]) - 0.1 * leverage_ratio[long_index] * enter_ratio[long_index]\n",
    "    short_profit = short_profit * enter_ratio[short_index]\n",
    "    long_profit = long_profit * enter_ratio[long_index]\n",
    "    now_profit[short_index] = short_profit\n",
    "    now_profit[long_index] = long_profit\n",
    "\n",
    "    return now_profit\n",
    "\n",
    "\n",
    "\n",
    "def after_forward(model, prob, now_profit, leverage_ratio, enter_ratio, pos_list, device):\n",
    "    ch_size = len(now_profit)\n",
    "    now_profit_tensor = now_profit.unsqueeze(dim=1)\n",
    "    leverage_ratio_tensor = leverage_ratio.unsqueeze(dim=1).to(torch.float32)\n",
    "    enter_ratio_tensor = enter_ratio.unsqueeze(dim=1)\n",
    "    mapping = {0: 0, 1: 1, 2: 2}  # Adjusted mapping\n",
    "    mapped_array = pos_list\n",
    "    step = torch.arange(0, ch_size * 3, step=3, device=device)\n",
    "\n",
    "    x = torch.cat([prob, now_profit_tensor, leverage_ratio_tensor, enter_ratio_tensor], dim=1)\n",
    "    cate_x = mapped_array + step\n",
    "\n",
    "    x = x.to(torch.float32).to(device)\n",
    "    cate_x = cate_x.to(device).long()\n",
    "\n",
    "\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    after_output = model.after_forward(x=x.squeeze(dim=0), x_cate=cate_x)\n",
    "    print(f'total runtime: {time.time() - start_time} second')\n",
    "    return after_output.squeeze(dim=0)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_fitness(metrics):\n",
    "    chromosomes_size = len(metrics)\n",
    "    \n",
    "    # Normalize metrics\n",
    "    def normalize_metric(metric, higher_is_better=True):\n",
    "        valid_indices = metric != -1e9\n",
    "        valid_metric = metric[valid_indices]\n",
    "        if len(valid_metric) == 0:\n",
    "            return np.zeros_like(metric)\n",
    "        min_val = np.nanmin(valid_metric)\n",
    "        max_val = np.nanmax(valid_metric)\n",
    "        if min_val == max_val:\n",
    "            normalized = np.ones_like(metric) if higher_is_better else np.zeros_like(metric)\n",
    "        else:\n",
    "            if higher_is_better:\n",
    "                normalized = (metric - min_val) / (max_val - min_val + 1e-8)\n",
    "            else:\n",
    "                normalized = (max_val - metric) / (max_val - min_val + 1e-8)\n",
    "        normalized[~valid_indices] = 0.0  # Assign zero to invalid entries\n",
    "        return normalized\n",
    "\n",
    "    higher_is_better_list = [\n",
    "        True,   # 'mean_returns'\n",
    "        True,   # 'sharpe_ratios'\n",
    "        True,   # 'sortino_ratios'\n",
    "        True,   # 'profit_factors'\n",
    "        True,   # 'win_rates'\n",
    "        False,  # 'max_drawdowns'\n",
    "        True    # cumulative_returns\n",
    "    ]\n",
    "    for index in range(len(higher_is_better_list)):\n",
    "        metrics[:, index] = normalize_metric(metrics[:, index], higher_is_better=higher_is_better_list[index])\n",
    "\n",
    "    # weights 배열을 metrics 순서에 맞춰서 재정렬\n",
    "    weights = [\n",
    "        0.2,  # mean_returns: 0\n",
    "        0.05,  # sharpe_ratios: 1\n",
    "        0.10,  # sortino_ratios: 2\n",
    "        0.10,  # profit_factors: 3\n",
    "        0.15,  # win_rates: 4\n",
    "        0.2,  # max_drawdowns: 5\n",
    "        0.2  # cumulative_returns\n",
    "    ]\n",
    "    # Calculate the final fitness values\n",
    "    fitness_values = np.zeros(chromosomes_size)\n",
    "    for index in range(len(weights)):\n",
    "        fitness_values += weights[index] * metrics[:, index]\n",
    "\n",
    "    # Penalize chromosomes with invalid fitness\n",
    "    fitness_values[metrics[:, 0] == -1e9] = -1e9\n",
    "\n",
    "    return fitness_values\n",
    "\n",
    "def fitness_fn(prescriptor, data, probs, entry_index_list, entry_pos_list, skip_data_cnt, start_data_cnt, chromosomes_size, window_size,\n",
    "               alpha=1., cut_percent=90., device='cpu', stop_cnt=1e9, profit_init=10, limit=4, minimum_date=40):\n",
    "    # Initialize variables\n",
    "    if stop_cnt != 1e9:\n",
    "        simulation_date = days_difference(data.iloc[entry_index_list[start_data_cnt]]['Open time'], data.iloc[entry_index_list[stop_cnt]]['Open time'])\n",
    "    else:\n",
    "        simulation_date = days_difference(data.iloc[entry_index_list[start_data_cnt]]['Open time'], data.iloc[-1]['Open time'])\n",
    "    ic(simulation_date)\n",
    "    pos_list = torch.zeros(chromosomes_size, dtype=torch.long, device=device)  # 0: 'hold'\n",
    "    price_list = torch.full((chromosomes_size,), -1.0, dtype=torch.float32, device=device)\n",
    "    leverage_ratio = torch.full((chromosomes_size,), -1, dtype=torch.int, device=device)\n",
    "    enter_ratio = torch.full((chromosomes_size,), -1.0, dtype=torch.float32, device=device)\n",
    "    profit = torch.zeros((chromosomes_size,), dtype=torch.float32, device=device)\n",
    "    additional_count = torch.zeros(chromosomes_size, dtype=torch.long, device=device)\n",
    "    returns_list = []\n",
    "    before_index = 0\n",
    "\n",
    "    # Map entry positions\n",
    "    entry_pos_mapping = {'hold': 0, 'short': 1, 'long': 2}\n",
    "    entry_pos_list_int = [entry_pos_mapping[ep] for ep in entry_pos_list]\n",
    "\n",
    "    import time  # Import time module for runtime measurement\n",
    "\n",
    "    for data_cnt, (entry_index, entry_pos) in tqdm(enumerate(zip(entry_index_list, entry_pos_list_int)), total=len(entry_pos_list_int)):\n",
    "        if data_cnt >= stop_cnt:\n",
    "            break\n",
    "        if data_cnt < start_data_cnt:\n",
    "            continue\n",
    "\n",
    "        entry_pos = torch.tensor(entry_pos).long()\n",
    "        x = data.iloc[entry_index]\n",
    "        curr_open = torch.tensor(x['Open'], dtype=torch.float32, device=device)\n",
    "        curr_close = torch.tensor(x['Close'], dtype=torch.float32, device=device)\n",
    "        curr_high = torch.tensor(x['High'], dtype=torch.float32, device=device)\n",
    "        curr_low = torch.tensor(x['Low'], dtype=torch.float32, device=device)\n",
    "        upper = torch.tensor(x[f'Upper_BB_{window_size}'], dtype=torch.float32, device=device)\n",
    "        lower = torch.tensor(x[f'Lower_BB_{window_size}'], dtype=torch.float32, device=device)\n",
    "        \n",
    "        history_x = data.iloc[before_index+1:entry_index+1]\n",
    "        history_high = torch.tensor(history_x['High'].max(), dtype=torch.float32, device=device)\n",
    "        history_low = torch.tensor(history_x['Low'].min(), dtype=torch.float32, device=device)\n",
    "\n",
    "        \n",
    "        pos_list, price_list, leverage_ratio, enter_ratio, additional_count, profit = loss_cut_fn(\n",
    "            pos_list, price_list, leverage_ratio,\n",
    "            enter_ratio, profit, history_low, history_high,\n",
    "            additional_count, alpha, cut_percent\n",
    "        )\n",
    "        \n",
    "        prob = torch.tensor(probs[:, data_cnt-skip_data_cnt]).to(device)\n",
    "        hold_pos = torch.where(pos_list == 0)[0]\n",
    "        same_pos = torch.where(pos_list == entry_pos)[0]\n",
    "        diff_pos = torch.where((pos_list != entry_pos) & (pos_list != 0))[0]\n",
    "        \n",
    "        now_profit = calculate_now_profit(pos_list, price_list, leverage_ratio, enter_ratio, curr_close)\n",
    "        prob = after_forward(prescriptor, prob, now_profit, leverage_ratio, enter_ratio, pos_list, device=device)\n",
    "        same_prob = prob[same_pos]\n",
    "        diff_prob = prob[diff_pos]\n",
    "        hold_prob = prob[hold_pos]\n",
    "        \n",
    "\n",
    "        pos_list[same_pos], price_list[same_pos], leverage_ratio[same_pos], enter_ratio[same_pos], additional_count[same_pos], profit[same_pos] = calculate_same(\n",
    "            same_prob, pos_list[same_pos], price_list[same_pos], leverage_ratio[same_pos], enter_ratio[same_pos], profit[same_pos],\n",
    "            entry_pos, curr_close, additional_count[same_pos], limit\n",
    "        )\n",
    "                \n",
    "        pos_list[diff_pos], price_list[diff_pos], leverage_ratio[diff_pos], enter_ratio[diff_pos], additional_count[diff_pos], profit[diff_pos] = calculate_diff(\n",
    "            diff_prob, pos_list[diff_pos], price_list[diff_pos], leverage_ratio[diff_pos], enter_ratio[diff_pos], profit[diff_pos],\n",
    "            entry_pos, curr_close, additional_count[diff_pos]\n",
    "        )\n",
    "                \n",
    "        pos_list[hold_pos], price_list[hold_pos], leverage_ratio[hold_pos], enter_ratio[hold_pos], additional_count[hold_pos], profit[hold_pos] = calculate_hold(\n",
    "            hold_prob, pos_list[hold_pos], price_list[hold_pos], leverage_ratio[hold_pos], enter_ratio[hold_pos], profit[hold_pos],\n",
    "            entry_pos, curr_close, additional_count[hold_pos]\n",
    "        )\n",
    "\n",
    "        before_index = entry_index\n",
    "        returns_list.append(profit.clone().cpu().detach().numpy())\n",
    "        profit = torch.zeros(chromosomes_size, dtype=torch.float32, device=device)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    returns_list = np.array(returns_list).T  # Shape: (chromosomes_size, time_steps)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    metrics = calculate_performance_metrics(returns_list, minimum_date=simulation_date)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def get_chromosome_key(chromosome):\n",
    "    # Quantize the chromosome values to 6 decimal places to handle floating-point precision\n",
    "    quantized_chrom = np.round(chromosome.cpu().numpy(), decimals=6)\n",
    "    # Convert to tuple to make it hashable\n",
    "    return tuple(quantized_chrom.flatten())\n",
    "\n",
    "def generation_valid(data_1m, dataset_1m, dataset_1d, prescriptor, evolution,\n",
    "                     skip_data_cnt, valid_skip_data_cnt, test_skip_data_cnt, chromosomes_size,\n",
    "                     window_size, gen_loop, best_size, elite_size, profit_init, \n",
    "                     entry_index_list=None, entry_pos_list=None,\n",
    "                     best_profit=None, best_chromosomes=None, start_gen=0, device='cuda:0',\n",
    "                     warming_step=5):\n",
    "    \n",
    "    best_profit = best_profit\n",
    "    best_chromosomes = best_chromosomes\n",
    "    # Create a temporary folder to save the generation data\n",
    "    temp_dir = 'generation_t'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    for gen_idx in range(start_gen, gen_loop):\n",
    "        print(f'generation  {gen_idx}: ')\n",
    "\n",
    "        logits = inference(dataset_1m, dataset_1d, prescriptor, device)\n",
    "        probs = []\n",
    "        for logit in logits:\n",
    "            logit = torch.stack(logit, dim=0)\n",
    "            probs.append(logit)\n",
    "        probs = torch.concat(probs, dim=1)\n",
    "        probs = probs.squeeze(dim=2)\n",
    "        \n",
    "        train_metrics = fitness_fn(\n",
    "            prescriptor=prescriptor,\n",
    "            data=data_1m,\n",
    "            probs=probs,\n",
    "            entry_index_list=entry_index_list,\n",
    "            entry_pos_list=entry_pos_list,\n",
    "            skip_data_cnt=skip_data_cnt,\n",
    "            start_data_cnt=skip_data_cnt,\n",
    "            chromosomes_size=chromosomes_size,\n",
    "            window_size=window_size,\n",
    "            alpha=1,\n",
    "            cut_percent=90,\n",
    "            device=device,\n",
    "            stop_cnt=valid_skip_data_cnt,\n",
    "            profit_init=profit_init,\n",
    "            limit=4\n",
    "        )\n",
    "        # profit = np.concatenate([profit]).T\n",
    "        if warming_step <= gen_idx:\n",
    "            if gen_idx != 0:\n",
    "                valid_metrics = fitness_fn(\n",
    "                    prescriptor=prescriptor,\n",
    "                    data=data_1m,\n",
    "                    probs=probs,\n",
    "                    entry_index_list=entry_index_list,\n",
    "                    entry_pos_list=entry_pos_list,\n",
    "                    skip_data_cnt=skip_data_cnt,\n",
    "                    start_data_cnt=valid_skip_data_cnt,\n",
    "                    chromosomes_size=chromosomes_size,\n",
    "                    window_size=window_size,\n",
    "                    alpha=1,\n",
    "                    cut_percent=90,\n",
    "                    device=device,\n",
    "                    stop_cnt=test_skip_data_cnt,\n",
    "                    profit_init=profit_init,\n",
    "                    limit=4\n",
    "                )\n",
    "                \n",
    "                valid_metrics = torch.from_numpy(valid_metrics[:elite_size])\n",
    "                \n",
    "                # Initialize best fitness and chromosomes if not already done\n",
    "                if best_profit is None:\n",
    "                    best_profit = valid_metrics\n",
    "                    best_chromosomes, _, _, _ = evolution.flatten_chromosomes()\n",
    "                    best_chromosomes = torch.tensor(best_chromosomes[:elite_size]).clone()\n",
    "                else:\n",
    "                    # Flatten current chromosomes\n",
    "                    chromosomes, _, _, _ = evolution.flatten_chromosomes()\n",
    "                    chromosomes = chromosomes[:elite_size].clone()\n",
    "                    \n",
    "                    # Find indices of new fitness values not in best fitness\n",
    "                    new_indices = [index for index, t in enumerate(valid_metrics) if t not in best_profit]\n",
    "                    \n",
    "                    # Update fitness and chromosomes with new values\n",
    "                    new_fitness = deepcopy(valid_metrics[new_indices])\n",
    "                    new_chromosomes = chromosomes[new_indices]\n",
    "                    \n",
    "                    best_profit = torch.concat([best_profit, new_fitness])\n",
    "                    best_chromosomes = torch.concat([best_chromosomes, torch.tensor(new_chromosomes)])\n",
    "\n",
    "                if len(best_chromosomes) > best_size:\n",
    "                    print('check_discard')\n",
    "                    valid_fitness = calculate_fitness(deepcopy(best_profit).numpy())\n",
    "                    # Select elite chromosomes based on best fitness\n",
    "                    elite_idx, elite_chromosomes = evolution.select_elite(torch.from_numpy(valid_fitness), best_chromosomes, best_size)\n",
    "\n",
    "                    # Update best fitness and chromosomes with elite values\n",
    "                    best_profit = best_profit[elite_idx]\n",
    "                    best_chromosomes = elite_chromosomes\n",
    "\n",
    "            \n",
    "\n",
    "        # Save current generation values to a file\n",
    "        gen_data = {\n",
    "            \"generation\": gen_idx,\n",
    "            \"prescriptor_state_dict\": prescriptor.state_dict(),\n",
    "            \"best_profit\": best_profit,\n",
    "            \"best_chromosomes\": best_chromosomes,\n",
    "\n",
    "        }\n",
    "        torch.save(gen_data, os.path.join(temp_dir, f'generation_{gen_idx}.pt')) \n",
    "        \n",
    "        train_fitness = calculate_fitness(train_metrics)\n",
    "        evolution.evolve(torch.from_numpy(train_fitness))\n",
    "        prescriptor = prescriptor.to(device)\n",
    "        \n",
    "        del logits\n",
    "        del probs\n",
    "    return best_chromosomes, best_profit\n",
    "\n",
    "def generation_test(data_1m, dataset_1m, dataset_1d, prescriptor, skip_data_cnt,\n",
    "                     start_data_cnt, end_data_cnt, chromosomes_size,\n",
    "                     window_size, profit_init, \n",
    "                     entry_index_list=None, entry_pos_list=None, device='cuda:0'):\n",
    "    \n",
    "    logits = inference(dataset_1m, dataset_1d, prescriptor, device)\n",
    "    probs = []\n",
    "    for logit in logits:\n",
    "        logit = torch.stack(logit, dim=0)\n",
    "        probs.append(logit)\n",
    "    probs = torch.concat(probs, dim=1)\n",
    "    probs = probs.squeeze(dim=2)\n",
    "    \n",
    "    profit = fitness_fn(\n",
    "        prescriptor=prescriptor,\n",
    "        data=data_1m,\n",
    "        probs=probs,\n",
    "        entry_index_list=entry_index_list,\n",
    "        entry_pos_list=entry_pos_list,\n",
    "        skip_data_cnt=skip_data_cnt,\n",
    "        start_data_cnt=start_data_cnt,\n",
    "        chromosomes_size=chromosomes_size,\n",
    "        window_size=window_size,\n",
    "        alpha=1,\n",
    "        cut_percent=90,\n",
    "        device=device,\n",
    "        stop_cnt=end_data_cnt,\n",
    "        profit_init=profit_init,\n",
    "        limit=4\n",
    "    )\n",
    "        \n",
    "       \n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosomes_size=10000\n",
    "window_size=240\n",
    "gen_loop=25\n",
    "best_size=10000\n",
    "elite_size=2000\n",
    "profit_init=1\n",
    "\n",
    "best_chromosomes, best_profit = generation_valid(\n",
    "    data_1m=data_1m,\n",
    "    dataset_1m=dataset_1m,\n",
    "    dataset_1d=dataset_1d,\n",
    "    prescriptor=prescriptor,\n",
    "    evolution=evolution,\n",
    "    skip_data_cnt=skip_data_cnt,\n",
    "    valid_skip_data_cnt=valid_skip_data_cnt,\n",
    "    test_skip_data_cnt=test_skip_data_cnt,\n",
    "    chromosomes_size=chromosomes_size,\n",
    "    window_size=window_size,\n",
    "    gen_loop=gen_loop,\n",
    "    best_size=best_size,\n",
    "    elite_size=elite_size,\n",
    "    profit_init=profit_init,\n",
    "    entry_index_list=bb_macd_entry_index_list,\n",
    "    entry_pos_list=entry_pos_list,\n",
    "    best_profit=best_profit,\n",
    "    best_chromosomes=best_chromosomes,\n",
    "    start_gen=start_gen,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-10000, -3, -1, 0, 1, 3, 5], dtype=torch.float32)\n",
    "(torch.nn.Softsign()(x) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Sigmoid()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x / (30 + torch.abs(x)) + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
