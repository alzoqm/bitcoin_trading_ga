from typing import List
from copy import deepcopy

import numpy as np
import torch

from ._base import BaseCrossover

# class UniformCrossover(BaseCrossover):
#     """n개의 parents에서 동일(1/n) 확률로 elements를 뽑는 crossover"""
    
#     def __init__(self, num_parents: int = 2):
#         """num_parents만큼 parent chromosome들을 뽑아서 
#         각 parents의 elements를 같은 확률로 랜덤하게 뽑음
#         """
#         self.num_parents = num_parents
#         self.prob_thd = np.cumsum([1. / num_parents] * num_parents)[::-1]
    
#     def __call__(self, parents: List[np.ndarray]) -> np.ndarray:
#         # 같은 확률로 각 parents의 개별 element를 선택함
#         # offspring = deepcopy(parents[0])
#         offspring = parents[0] # -> deepcopy 일단 제거
#         prob_arr = np.random.rand(*offspring.shape)
#         for i in range(1, self.num_parents):
#             threshold = self.prob_thd[i]
#             offspring = np.where(prob_arr <= threshold, parents[i], offspring)
#         return offspring

#     def get_num_parents(self) -> int:
#         return self.num_parents


class UniformCrossover(BaseCrossover):
    """n개의 parents에서 동일(1/n) 확률로 elements를 뽑는 crossover"""
    
    def __init__(self, num_parents: int = 2):
        """num_parents만큼 parent chromosome들을 뽑아서
        각 parents의 elements를 같은 확률로 랜덤하게 뽑음
        """
        self.num_parents = num_parents
        self.prob_thd = torch.cumsum(torch.tensor([1. / num_parents] * num_parents), dim=0).flip(dims=[0])
    
    # def __call__(self, parents: List[torch.Tensor]) -> torch.Tensor:
    #     # 같은 확률로 각 parents의 개별 element를 선택함
    #     offspring = parents[0].clone()  # deepcopy equivalent in PyTorch
    #     prob_arr = torch.rand_like(offspring)
        
    #     for i in range(1, self.num_parents):
    #         threshold = self.prob_thd[i]
    #         offspring = torch.where(prob_arr <= threshold, parents[i], offspring)
        
    #     return offspring

    def __call__(self, parents: torch.Tensor) -> torch.Tensor:
        # 같은 확률로 각 parents의 개별 element를 선택함
        offspring = parents[:, 0].clone()  # deepcopy equivalent in PyTorch
        prob_arr = torch.rand_like(offspring)
        
        for i in range(1, self.num_parents):
            threshold = self.prob_thd[i]
            offspring = torch.where(prob_arr <= threshold, parents[:, i], offspring)
        
        return offspring
    
    def get_num_parents(self) -> int:
        return self.num_parents

class DifferentialEvolutionOperator(BaseCrossover):
    """Differential Evolution operator that performs mutation and crossover."""
    
    def __init__(self, F: float = 0.5, CR: float = 0.9):
        """Initialize the mutation factor F and crossover rate CR."""
        self.F = F  # Mutation scaling factor
        self.CR = CR  # Crossover probability
        self.num_parents = 4
    
    def __call__(self, parents: torch.Tensor) -> torch.Tensor:
        """Perform mutation and crossover to generate trial vectors.
        
        Args:
            parents: A tensor of shape (batch_size, 4, D), where D is the dimension.
                     parents[:, 0, :] is the target vector x_i.
                     parents[:, 1, :], parents[:, 2, :], parents[:, 3, :] are x_r1, x_r2, x_r3.
        Returns:
            Trial vectors generated by DE, of shape (batch_size, D).
        """
        x_i = parents[:, 0, :]  # Target vectors
        x_r1 = parents[:, 1, :]  # Random vector 1
        x_r2 = parents[:, 2, :]  # Random vector 2
        x_r3 = parents[:, 3, :]  # Random vector 3
        
        batch_size, D = x_i.shape
        
        # Mutation: v_i = x_r1 + F * (x_r2 - x_r3)
        v_i = x_r1 + self.F * (x_r2 - x_r3)
        
        # Crossover (binomial): create trial vector u_i
        # Ensure at least one parameter is from the mutant vector
        j_rand = torch.randint(0, D, (batch_size, 1))
        rand_j = torch.rand(batch_size, D)
        j_indices = torch.arange(D).expand(batch_size, D)
        
        # Crossover mask
        mask = (rand_j <= self.CR) | (j_indices == j_rand)
        
        # Trial vector: u_i
        u_i = torch.where(mask, v_i, x_i)
        
        return u_i

    def get_num_parents(self) -> int:
        return self.num_parents

import torch
from torch import Tensor

# If you are using a library that requires a specific base class, keep it.
# Otherwise, you can omit or adapt this part.
class BaseCrossover:
    def get_num_parents(self) -> int:
        raise NotImplementedError

class CenDE_DOBLOperator(BaseCrossover):
    """
    A simplified demonstration of a 'CenDE-DOBL' style operator that:
      1) Uses DE/local-to-best/1 mutation.
      2) Applies binomial crossover.
      3) With probability Jr, applies an OBL transform to the trial vector.
         Otherwise, replaces the trial with a centroid-based vector.
         
    NOTE: The full CenDE-DOBL algorithm typically requires population-level
    operations. This example is a single-operator approximation for demonstration.
    """

    def __init__(
        self,
        F: float = 0.5,     # Mutation scaling factor
        CR: float = 0.9,    # Crossover probability
        Jr: float = 0.3,    # Probability of applying OBL vs centroid approach
        lower_bound: float = -5.0,
        upper_bound: float =  5.0
    ):
        """
        Args:
            F (float):     DE scaling factor for the mutation step.
            CR (float):    Binomial crossover probability.
            Jr (float):    Jumping rate controlling how often OBL is used.
            lower_bound (float): Lower bound for clamping the solution.
            upper_bound (float): Upper bound for clamping the solution.
        """
        super().__init__()
        self.F = F
        self.CR = CR
        self.Jr = Jr
        self.L = lower_bound
        self.U = upper_bound
        
        # We expect five parents per offspring: x_i, x_best, x_r1, x_r2, x_r3
        self.num_parents = 5  

    def __call__(self, parents: Tensor) -> Tensor:
        """
        Perform local-to-best mutation, binomial crossover, 
        then either OBL or centroid-based replacement.
        
        Args:
            parents (Tensor): A float tensor of shape (batch_size, 5, D).
              - parents[:, 0, :] => x_i (target)
              - parents[:, 1, :] => x_best
              - parents[:, 2, :] => x_r1
              - parents[:, 3, :] => x_r2
              - parents[:, 4, :] => x_r3
              
        Returns:
            A Tensor of shape (batch_size, D) containing the new trial vectors.
        """
        # Unpack parents
        x_i    = parents[:, 0, :]  # Target
        x_best = parents[:, 1, :]  # Best
        x_r1   = parents[:, 2, :]
        x_r2   = parents[:, 3, :]
        x_r3   = parents[:, 4, :]

        batch_size, D = x_i.shape

        # --- 1) DE/local-to-best/1 mutation ---
        # v_i = x_i + F*(x_best - x_i) + F*(x_r1 - x_r2)
        v_i = x_i + self.F * (x_best - x_i) + self.F * (x_r1 - x_r2)
        
        # (If you want to use x_r3 in your strategy, adapt accordingly)

        # --- 2) Binomial crossover ---
        # Ensure at least one parameter is from the mutant vector v_i
        j_rand = torch.randint(0, D, (batch_size, 1))
        rand_j = torch.rand(batch_size, D)
        j_indices = torch.arange(D).expand(batch_size, D)
        
        mask = (rand_j <= self.CR) | (j_indices == j_rand)
        u_i = torch.where(mask, v_i, x_i)

        # --- 3) Bound Clamping ---
        u_i = torch.clamp(u_i, self.L, self.U)
        
        # --- 4) Dynamic OBL or Centroid-based Strategy ---
        # With probability Jr, do an OBL transform on u_i.
        # Otherwise, replace with a centroid of the 5 parent vectors.
        
        # OBL transform: x_opp = L + U - x
        x_opp = self.L + self.U - u_i
        
        # Simple centroid over the five parents
        centroid = (x_i + x_best + x_r1 + x_r2 + x_r3) / 5.0
        
        # Generate random mask to decide OBL vs Centroid per batch instance
        random_tensor = torch.rand((batch_size, 1), device=u_i.device)
        random_tensor = random_tensor.expand(batch_size, D)
        
        # If random < Jr => OBL, else => centroid
        final_mask = (random_tensor < self.Jr)
        final_u_i  = torch.where(final_mask, x_opp, centroid)

        return final_u_i

    def get_num_parents(self) -> int:
        """
        Return the number of parents needed for each offspring.
        CenDE-DOBL in this demonstration uses 5:
          x_i, x_best, x_r1, x_r2, x_r3
        """
        return self.num_parents

class WeightedSumCrossover(BaseCrossover):
    """n개의 parents를 weighted sum하는 crossover"""
    
    def __init__(self, weights: List[float] = [0.5, 0.5]):
        """weights의 길이에 따라 num_parents가 정해짐"""
        self.weights = torch.tensor(weights).reshape(-1, 1)
    
    # def __call__(self, parents: List[torch.Tensor]) -> torch.Tensor:
    #     return torch.sum(self.weights * torch.stack(parents), axis=0)
    
    def __call__(self, parents: List[torch.Tensor]) -> torch.Tensor:
        return torch.sum(self.weights * parents, axis=1)

    def get_num_parents(self) -> int:
        return len(self.weights)
