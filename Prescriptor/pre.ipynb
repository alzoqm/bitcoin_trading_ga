{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/daily/bit')\n",
    "\n",
    "from Prescriptor import Prescriptor\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "group = 30\n",
    "\n",
    "small_lstm_x = torch.randn(size=(512, 240, 19)).to(device).float()\n",
    "large_lstm_x = torch.randn(size=(512, 60, 19)).to(device).float()\n",
    "base_x = torch.randn(size=(1, 6)).to(device).float()\n",
    "base_x = torch.concat([base_x for i in range(group)])\n",
    "cate_x = torch.randint(0, 3, size=(group, )).to(device)\n",
    "step = torch.arange(0, group*3, step=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600840"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "pres = Prescriptor(basic_block=None, \n",
    "                          base_small_input_dim=19, \n",
    "                          base_large_input_dim=19,\n",
    "                          base_hidden_dim=24, \n",
    "                          base_output_dim=16, \n",
    "                          after_input_dim=22, \n",
    "                          after_hidden_dim=32, \n",
    "                          after_output_dim=6, \n",
    "                          num_blocks=group).to(device)\n",
    "selection = RouletteSelection(elite_num=200,\n",
    "                             parents_num=400,\n",
    "                             minimize=False)\n",
    "\n",
    "crossover = UniformCrossover()\n",
    "# mutation = ChainMutation([AddNormalMutation(mut_prob=0.2), \n",
    "#                           MultiplyUniformMutation(mut_prob=0.2), \n",
    "#                           FlipSignMutation(0.07)])\n",
    "mutation = AddNormalMutation(mut_prob=0.1)\n",
    "\n",
    "# *** Evolution instance\n",
    "evolution = Evolution(\n",
    "                    prescriptor=pres,\n",
    "                    selection=selection,\n",
    "                    crossover=crossover,\n",
    "                    mutation=mutation,)\n",
    "get_n_params(pres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(34):\n",
    "        lstm_logit = pres.base_forward(small_lstm_x, large_lstm_x).squeeze(dim=2)\n",
    "        # lstm_logit = torch.concat(lstm_logit, dim=1).to(device)\n",
    "        break\n",
    "lstm_logit = lstm_logit.permute([1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres.eval()\n",
    "pres.to(device)\n",
    "for i in range(17000):\n",
    "    with torch.no_grad():\n",
    "        after_input = torch.concat([lstm_logit[0].cuda(), base_x.cuda()], dim=1)\n",
    "        after_output = pres.after_forward(x=after_input, x_cate=cate_x+step)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitness = torch.sum(after_output.squeeze(dim=0), dim=1).cpu()\n",
    "# evolution.evolve(fitness)\n",
    "chromosomes, base_ch_shape, after_ch_shape, device = evolution.flatten_chromosomes()\n",
    "evolution.update_chromosomes(chromosomes, base_ch_shape, after_ch_shape, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(34):\n",
    "        lstm_logit_2 = pres.base_forward(small_lstm_x, large_lstm_x).squeeze(dim=2)\n",
    "        # lstm_logit = torch.concat(lstm_logit, dim=1).to(device)\n",
    "        break\n",
    "lstm_logit_2 = lstm_logit_2.permute([1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres.eval()\n",
    "pres.to(device)\n",
    "for i in range(17000):\n",
    "    with torch.no_grad():\n",
    "        after_input_2 = torch.concat([lstm_logit_2[0].cuda(), base_x.cuda()], dim=1)\n",
    "        after_output_2 = pres.after_forward(x=after_input_2, x_cate=cate_x+step)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg     \tstd     \tmin     \tmax     \n",
      "0  \t50    \t0.478552\t0.220469\t0.243774\t0.759626\n",
      "1  \t37    \t0.654953\t0.176367\t0.225834\t0.776958\n",
      "2  \t42    \t0.677962\t0.154839\t0.2532  \t0.774083\n",
      "3  \t43    \t0.711727\t0.121391\t0.352406\t0.78221 \n",
      "4  \t36    \t0.751184\t0.0610176\t0.334909\t0.78221 \n",
      "5  \t36    \t0.756362\t0.0708008\t0.266108\t0.78221 \n",
      "6  \t44    \t0.738317\t0.0999812\t0.290931\t0.78221 \n",
      "7  \t39    \t0.746673\t0.100134 \t0.25953 \t0.78221 \n",
      "8  \t41    \t0.753659\t0.0788583\t0.245736\t0.78221 \n",
      "9  \t37    \t0.771179\t0.0126803\t0.715897\t0.78221 \n",
      "10 \t42    \t0.747074\t0.107691 \t0.253614\t0.78221 \n",
      "11 \t41    \t0.762735\t0.0743486\t0.272632\t0.78221 \n",
      "12 \t42    \t0.766622\t0.0724094\t0.272632\t0.78221 \n",
      "13 \t42    \t0.752404\t0.104297 \t0.25378 \t0.78221 \n",
      "14 \t41    \t0.757296\t0.103593 \t0.255826\t0.78221 \n",
      "15 \t40    \t0.766976\t0.073535 \t0.260304\t0.78221 \n",
      "16 \t36    \t0.778491\t0.0138444\t0.695746\t0.78221 \n",
      "17 \t42    \t0.770279\t0.068797 \t0.291152\t0.78221 \n",
      "18 \t45    \t0.743999\t0.124993 \t0.250712\t0.78221 \n",
      "19 \t40    \t0.758999\t0.0782086\t0.282224\t0.78221 \n",
      "20 \t44    \t0.767583\t0.0739535\t0.282224\t0.78221 \n",
      "21 \t36    \t0.75955 \t0.0953498\t0.288249\t0.78221 \n",
      "22 \t40    \t0.77527 \t0.0206142\t0.668159\t0.78221 \n",
      "23 \t39    \t0.767597\t0.0734847\t0.267103\t0.78221 \n",
      "24 \t35    \t0.755023\t0.0950484\t0.282224\t0.78221 \n",
      "25 \t39    \t0.775799\t0.0224149\t0.634298\t0.784587\n",
      "26 \t34    \t0.77083 \t0.0700381\t0.282224\t0.784587\n",
      "27 \t38    \t0.764883\t0.0787669\t0.223015\t0.784587\n",
      "28 \t41    \t0.733218\t0.137094 \t0.225005\t0.784587\n",
      "29 \t40    \t0.745802\t0.120527 \t0.246234\t0.784587\n",
      "30 \t33    \t0.767467\t0.0782524\t0.255826\t0.784587\n",
      "31 \t45    \t0.764167\t0.0863974\t0.23034 \t0.784587\n",
      "32 \t35    \t0.776518\t0.0507056\t0.422119\t0.784587\n",
      "33 \t36    \t0.766705\t0.0718708\t0.350333\t0.784587\n",
      "34 \t41    \t0.758662\t0.0963543\t0.246234\t0.784587\n",
      "35 \t35    \t0.761633\t0.0933929\t0.255826\t0.784587\n",
      "36 \t35    \t0.736649\t0.144516 \t0.253918\t0.784587\n",
      "37 \t45    \t0.753601\t0.119171 \t0.227382\t0.784587\n",
      "38 \t26    \t0.762725\t0.100674 \t0.266302\t0.784587\n",
      "39 \t35    \t0.772329\t0.067576 \t0.307599\t0.784587\n",
      "40 \t38    \t0.772871\t0.0718418\t0.271111\t0.784587\n",
      "\n",
      "최적의 개체:\n",
      "Node 0: Feature 4, Threshold 13.9025\n",
      "Node 1: Feature 10, Threshold 31623.7059\n",
      "Node 2: Feature 5, Threshold 3.0525\n",
      "Node 3: Leaf - Class 0\n",
      "Node 4: Leaf - Class 1\n",
      "Node 5: Leaf - Class 1\n",
      "Node 6: Leaf - Class 0\n",
      "\n",
      "훈련 정확도: 0.7846\n",
      "검증 정확도: 0.7803\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
