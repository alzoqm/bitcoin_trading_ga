{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations_2 import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, cyclic_encode_fn, calculate_support_resistance_numba\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn, simple_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions_bi_cul import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor, CryptoModelTCN\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator, CenDE_DOBLOperator, SkipCrossover\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_1m = load_data_1m('/root/daily/bit/data/1min_ethusdt.pkl')\n",
    "\n",
    "# For 1M Data\n",
    "# 다양한 window size 설정 (필요에 따라 추가/수정 가능)\n",
    "ma_windows       = [20, 60, 180, 240]         # 이동평균 (MA)의 window size\n",
    "bb_windows       = [20, 60, 240]               # Bollinger Bands의 window size\n",
    "macd_params      = [(60, 600, 240), (30, 300, 120)]  # (short, long, signal) 설정 예시\n",
    "rsi_windows      = [14, 60]                    # RSI window size (기본: 14)\n",
    "stoch_params     = [(20, 60), (240, 60)]         # (stochastic window, period)\n",
    "adx_windows      = [14, 60, 240]               # ADX window size\n",
    "atr_windows      = [14, 60, 240]               # ATR window size\n",
    "williams_windows = [14, 60, 240]               # Williams %R window size\n",
    "sr_windows       = [20, 60, 240]               # Support/Resistance 탐색 window size\n",
    "\n",
    "# MA: 'EMA' 대신 'MA' 사용\n",
    "for window in ma_windows:\n",
    "    data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, window, 'MA')\n",
    "\n",
    "# Bollinger Bands (여기서는 기존 함수 사용, window에 따라 값이 달라짐)\n",
    "for window in bb_windows:\n",
    "    data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, window)\n",
    "\n",
    "# MACD: 여러 파라미터 조합 적용\n",
    "for short_win, long_win, signal_win in macd_params:\n",
    "    data_1m, macd_cols = calculate_macd(data_1m, short_win, long_win, signal_win)\n",
    "\n",
    "# RSI\n",
    "for window in rsi_windows:\n",
    "    data_1m, rsi_cols = calculate_rsi(data_1m, window=window)\n",
    "\n",
    "# Stochastic Oscillator\n",
    "for stoch_win, period in stoch_params:\n",
    "    data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, stoch_win, period)\n",
    "\n",
    "# ADX\n",
    "for window in adx_windows:\n",
    "    data_1m, adx_cols = calculate_adx(data_1m, window)\n",
    "\n",
    "# ATR\n",
    "for window in atr_windows:\n",
    "    data_1m, atr_cols = calculate_atr(data_1m, window)\n",
    "\n",
    "# OBV: window이 필요없는 경우 한번만 계산\n",
    "data_1m, obv_cols = calculate_obv(data_1m)\n",
    "\n",
    "# Williams %R\n",
    "for window in williams_windows:\n",
    "    data_1m, will_cols = calculate_williams_r(data_1m, window)\n",
    "\n",
    "# Support/Resistance (Numba 이용)\n",
    "for window in sr_windows:\n",
    "    data_1m, sr_col = calculate_support_resistance_numba(data_1m, window=window)\n",
    "\n",
    "# 기본 feature 및 cyclic encoding (필요에 따라 한 번만 계산)\n",
    "data_1m, base_feature    = base_feature_fn(data_1m, alpha=100)\n",
    "data_1m, cyclic_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "# Prepare Feature Columns\n",
    "drop_column = [\n",
    "    'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "    'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "]\n",
    "\n",
    "test_column = ['Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
    "               'Taker buy quote asset volume']\n",
    "feature_column = (\n",
    "    test_column + cyclic_encoding + ma_cols_rel + bb_cols_rel + rsi_cols + macd_cols + stoch_cols +\n",
    "    adx_cols + will_cols + sr_col + base_feature  # Excluding obv and atr\n",
    ")\n",
    "# feature_column_1d = (\n",
    "#     test_column + cyclice_encoding_1d + ma_cols_rel_1d + bb_cols_rel_1d + rsi_cols_1d + macd_cols_1d + stoch_cols_1d +\n",
    "#     adx_cols_1d + will_cols_1d + sr_col_1d + base_feature_1d\n",
    "# )\n",
    "\n",
    "\n",
    "# bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 240, 60, 180)\n",
    "# bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = simple_fitness_fn(data_1m, 240, 60, 180)\n",
    "# bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "\n",
    "# Prepare Dataset\n",
    "data_tensor = make_dataset(\n",
    "    data_1m, data_1d,\n",
    "    using_column=feature_column, using_column_1d=feature_column_1d,\n",
    "    window_size=240, window_size_1d=60,\n",
    "    entry_pos_list=bb_macd_entry_pos_list, patience_list=patience_list,\n",
    "    use_1d_data=True\n",
    ")\n",
    "entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "dataset_1m = []\n",
    "dataset_1d = []\n",
    "skip_data_cnt = 0\n",
    "for data in data_tensor:\n",
    "    if len(data[0]) == 240 and len(data[1]) == 60:\n",
    "        dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    "        dataset_1d.append(torch.from_numpy(data[1]).unsqueeze(dim=0))\n",
    "    else:\n",
    "        skip_data_cnt += 1\n",
    "dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "dataset_1d = torch.cat(dataset_1d, dim=0)\n",
    "\n",
    "# Avoid division by zero by replacing zero denominators with a small epsilon value\n",
    "epsilon = 1e-10\n",
    "dataset_1m[:, :, :4] = dataset_1m[:, :, :4] / (torch.mean(dataset_1m[:, :, :4], dim=1).unsqueeze(dim=1) + epsilon)\n",
    "dataset_1d[:, :, :4] = dataset_1d[:, :, :4] / (torch.mean(dataset_1d[:, :, :4], dim=1).unsqueeze(dim=1) + epsilon)\n",
    "\n",
    "dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "dataset_1d = replace_nan_with_zero(dataset_1d)\n",
    "\n",
    "import pickle\n",
    "\n",
    "data_to_save = {\n",
    "    'dataset_1m': dataset_1m,\n",
    "    'dataset_1d': dataset_1d,\n",
    "    'skip_data_cnt': skip_data_cnt,\n",
    "    'entry_pos_list': entry_pos_list,\n",
    "    'bb_macd_entry_pos_list': bb_macd_entry_pos_list,\n",
    "    'bb_macd_entry_index_list': bb_macd_entry_index_list\n",
    "}\n",
    "\n",
    "with open('/root/daily/bit_4/backup_feature_data/data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the file into separate variables\n",
    "with open('/root/daily/bit_4/backup_feature_data/data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "dataset_1m = loaded_data['dataset_1m']\n",
    "dataset_1d = loaded_data['dataset_1d']\n",
    "skip_data_cnt = loaded_data['skip_data_cnt']\n",
    "entry_pos_list = loaded_data['entry_pos_list']\n",
    "bb_macd_entry_pos_list = loaded_data['bb_macd_entry_pos_list']\n",
    "bb_macd_entry_index_list = loaded_data['bb_macd_entry_index_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_skip_data_cnt = int(len(dataset_1m)*0.6) + skip_data_cnt\n",
    "test_skip_data_cnt = int(len(dataset_1m)*0.8) + skip_data_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 521850000\n",
      "generation  0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [14:36<00:00, 43.85s/it]\n",
      " 61%|██████    | 25154/41319 [03:51<02:28, 108.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:09<00:00, 45.50s/it]\n",
      " 61%|██████    | 25154/41319 [05:47<03:43, 72.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:13<00:00, 45.67s/it]\n",
      " 61%|██████    | 25154/41319 [05:45<03:41, 72.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:16<00:00, 45.80s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 71.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:14<00:00, 45.70s/it]\n",
      " 61%|██████    | 25154/41319 [05:38<03:37, 74.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:11<00:00, 45.58s/it]\n",
      " 61%|██████    | 25154/41319 [05:48<03:44, 72.12it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 389.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:17<00:00, 45.90s/it]\n",
      " 61%|██████    | 25154/41319 [05:34<03:35, 75.15it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 389.32it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:15<00:00, 45.78s/it]\n",
      " 61%|██████    | 25154/41319 [05:48<03:43, 72.19it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 388.41it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:25<00:00, 46.29s/it]\n",
      " 61%|██████    | 25154/41319 [05:47<03:43, 72.28it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:21, 384.65it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:14<00:00, 45.71s/it]\n",
      " 61%|██████    | 25154/41319 [06:00<03:51, 69.69it/s] \n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.33it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:19<00:00, 45.97s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 72.01it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.11it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:13<00:00, 45.67s/it]\n",
      " 61%|██████    | 25154/41319 [05:46<03:42, 72.49it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 388.28it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:21<00:00, 46.07s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 72.01it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.10it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:13<00:00, 45.68s/it]\n",
      " 61%|██████    | 25154/41319 [05:50<03:45, 71.79it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.01it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:17<00:00, 45.90s/it]\n",
      " 61%|██████    | 25154/41319 [05:44<03:41, 73.00it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 386.64it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:11<00:00, 45.59s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 72.00it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.11it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:17<00:00, 45.86s/it]\n",
      " 61%|██████    | 25154/41319 [05:42<03:39, 73.54it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.06it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:14<00:00, 45.74s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 72.04it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:26<00:00, 46.32s/it]\n",
      " 61%|██████    | 25154/41319 [05:48<03:43, 72.22it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.32it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:17<00:00, 45.89s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 71.97it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.96it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:19<00:00, 45.98s/it]\n",
      " 61%|██████    | 25154/41319 [05:59<03:51, 69.94it/s]  \n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 386.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:18<00:00, 45.91s/it]\n",
      " 61%|██████    | 25154/41319 [05:42<03:40, 73.47it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.00it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:20<00:00, 46.00s/it]\n",
      " 61%|██████    | 25154/41319 [05:50<03:45, 71.81it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.25it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:12<00:00, 45.62s/it]\n",
      " 61%|██████    | 25154/41319 [05:26<03:29, 77.13it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.30it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:21<00:00, 46.06s/it]\n",
      " 61%|██████    | 25154/41319 [05:42<03:40, 73.48it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 386.51it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:12<00:00, 45.64s/it]\n",
      " 61%|██████    | 25154/41319 [05:40<03:38, 73.97it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 386.41it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:23<00:00, 46.18s/it]\n",
      " 61%|██████    | 25154/41319 [05:42<03:40, 73.36it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:17<00:00, 45.85s/it]\n",
      " 61%|██████    | 25154/41319 [05:46<03:42, 72.59it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:21, 382.56it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:21<00:00, 46.06s/it]\n",
      " 61%|██████    | 25154/41319 [05:37<03:37, 74.44it/s]\n",
      " 80%|████████  | 33236/41319 [01:26<00:20, 385.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:16<00:00, 45.84s/it]\n",
      " 61%|██████    | 25154/41319 [06:02<03:52, 69.48it/s]  \n",
      " 80%|████████  | 33236/41319 [01:26<00:21, 384.27it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:19<00:00, 45.98s/it]\n",
      " 61%|██████    | 25154/41319 [05:42<03:40, 73.48it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 386.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  31: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:19<00:00, 45.97s/it]\n",
      " 61%|██████    | 25154/41319 [05:49<03:44, 71.97it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.00it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  32: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [16:33<00:00, 49.68s/it]\n",
      " 61%|██████    | 25154/41319 [06:03<03:53, 69.24it/s]\n",
      " 80%|████████  | 33236/41319 [01:28<00:21, 374.84it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:12<00:00, 45.63s/it]\n",
      " 61%|██████    | 25154/41319 [05:43<03:41, 73.13it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.98it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  34: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:21<00:00, 46.06s/it]\n",
      " 61%|██████    | 25154/41319 [05:27<03:30, 76.90it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 387.22it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  35: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:16<00:00, 45.81s/it]\n",
      " 61%|██████    | 25154/41319 [05:56<03:49, 70.53it/s]  \n",
      " 80%|████████  | 33236/41319 [01:27<00:21, 381.98it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  36: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:21<00:00, 46.10s/it]\n",
      " 61%|██████    | 25154/41319 [05:50<03:45, 71.80it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 389.96it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  37: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 20/20 [15:12<00:00, 45.65s/it]\n",
      " 61%|██████    | 25154/41319 [05:50<03:45, 71.76it/s]\n",
      " 80%|████████  | 33236/41319 [01:25<00:20, 389.14it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  38: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress:  90%|█████████ | 18/20 [13:47<01:31, 45.81s/it]"
     ]
    }
   ],
   "source": [
    "# Evolution Setup\n",
    "# 전역적으로 기울기 계산 비활성화\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "chromosomes_size=30000\n",
    "window_size=240\n",
    "EPOCH = 5\n",
    "gen_loop=50\n",
    "best_size=30000\n",
    "elite_size=6000\n",
    "profit_init=1\n",
    "device = 'cuda:1'\n",
    "group = 30000\n",
    "start_gen = 0\n",
    "best_profit = None\n",
    "best_chromosomes = None\n",
    "\n",
    "# state_dict_path = '/root/daily/bit_3/generation/generation_36.pt'\n",
    "# if os.path.exists(state_dict_path):\n",
    "#     state_dict = torch.load(state_dict_path)\n",
    "#     start_gen = state_dict['generation'] + 1\n",
    "#     best_profit = state_dict['best_profit']\n",
    "#     best_chromosomes = state_dict['best_chromosomes']\n",
    "    # prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    prescriptor = Prescriptor(\n",
    "        basic_block=CryptoModelTCN, \n",
    "        small_input_dim=25, \n",
    "        large_input_dim=25,\n",
    "        fc_hidden_size=16,\n",
    "        small_lstm_hidden_dim=16,\n",
    "        large_lstm_hidden_dim=16,\n",
    "        output_dim=8, \n",
    "        after_input_dim=11, \n",
    "        after_hidden_dim=16, \n",
    "        after_output_dim=5, \n",
    "        num_blocks=group,\n",
    "    ).to(device).eval()\n",
    "\n",
    "    # if i == 1:\n",
    "    #     start_gen=0\n",
    "\n",
    "    # if i == 0:\n",
    "    #     prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "    total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "    print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "    selection = RouletteSelection(elite_num=6000, parents_num=6000, minimize=False)\n",
    "    # selection = ParetoLexsortSelection(elite_num=2000, parents_num=4000,\n",
    "    #                                     priority=[], prior_ratio= [],\n",
    "    #                                     prob_method= 'softmax',minimize=False)\n",
    "    # crossover = DifferentialEvolutionOperator()\n",
    "    # crossover = UniformCrossover(num_parents=4)\n",
    "    # crossover = CenDE_DOBLOperator()\n",
    "    mutation = ChainMutation([RandomValueMutation(mut_prob=0.05), AddUniformMutation(mut_prob=0.1)])\n",
    "    crossover = UniformCrossover(num_parents=1)\n",
    "    # mutation = AddNormalMutation(mut_prob=0.1)\n",
    "    evolution = Evolution(\n",
    "        prescriptor=prescriptor,\n",
    "        selection=selection,\n",
    "        crossover=crossover,\n",
    "        mutation=mutation\n",
    "    )\n",
    "\n",
    "    best_chromosomes, best_profit = generation_valid(\n",
    "        data_1m=data_1m,\n",
    "        dataset_1m=dataset_1m,\n",
    "        dataset_1d=dataset_1d,\n",
    "        prescriptor=prescriptor,\n",
    "        evolution=evolution,\n",
    "        skip_data_cnt=skip_data_cnt,\n",
    "        valid_skip_data_cnt=valid_skip_data_cnt,\n",
    "        test_skip_data_cnt=test_skip_data_cnt,\n",
    "        chromosomes_size=chromosomes_size,\n",
    "        window_size=window_size,\n",
    "        gen_loop=gen_loop,\n",
    "        best_size=best_size,\n",
    "        elite_size=elite_size,\n",
    "        profit_init=profit_init,\n",
    "        entry_index_list=bb_macd_entry_index_list,\n",
    "        entry_pos_list=entry_pos_list,\n",
    "        best_profit=best_profit,\n",
    "        best_chromosomes=best_chromosomes,\n",
    "        start_gen=start_gen,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
