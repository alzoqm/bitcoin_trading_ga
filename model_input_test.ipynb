{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations_2 import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr, calculate_volume,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, calculate_volatility_features, cyclic_encode_fn, calculate_support_resistance_numba, log_transform\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn, simple_fitness_fn, BB_MACD_EMA_RSI_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions_bi_cul import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor, CryptoModelTCN\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator, CenDE_DOBLOperator, SkipCrossover\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_1m = load_data_1m('/root/daily/bit/data/1min_bitusdt.pkl')\n",
    "# # data_1m = data_1m.iloc[:200000]\n",
    "\n",
    "# # 각 지표별 window 설정 및 계산\n",
    "# ma_windows = [5, 20, 60]\n",
    "# bb_windows = [5, 20, 60]\n",
    "# macd_windows = [(60, 600, 240), (30, 300, 120), (6, 13, 4)]\n",
    "# rsi_windows = [7, 20, 60]\n",
    "# stoch_windows = [(240, 60), (120, 30), (9, 3)]\n",
    "# adx_windows = [60, 20, 7]\n",
    "# atr_windows = [60, 20, 7]\n",
    "# williams_windows = [60, 20, 7]\n",
    "# sr_windows =  [120, 60, 20]\n",
    "\n",
    "# all_ma_cols, all_ma_cols_rel = [], []\n",
    "# all_bb_cols, all_bb_cols_rel = [], []\n",
    "# all_macd_cols = []\n",
    "# all_rsi_cols = []\n",
    "# all_stoch_cols = []\n",
    "# all_adx_cols = []\n",
    "# all_atr_cols = []\n",
    "# all_will_cols = []\n",
    "# all_sr_cols = []\n",
    " \n",
    "# for ws in ma_windows:\n",
    "#     data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, ws, 'MA')\n",
    "#     all_ma_cols.extend(ma_cols)\n",
    "#     all_ma_cols_rel.extend(ma_cols_rel)\n",
    " \n",
    "# data_1m, _, __ = calculate_MA_data(data_1m, 180, 'MA')\n",
    "# for ws in bb_windows:\n",
    "#     data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, ws)\n",
    "\n",
    "# for short_period, long_period, signal_period in macd_windows:\n",
    "#     data_1m, macd_cols = calculate_macd(data_1m, short_period, long_period, signal_period)\n",
    "#     all_macd_cols.extend(macd_cols)\n",
    " \n",
    "# for ws in rsi_windows:\n",
    "#     data_1m, rsi_cols = calculate_rsi(data_1m, window=ws)\n",
    "#     all_rsi_cols.extend(rsi_cols)\n",
    " \n",
    "# for k_period, d_period in stoch_windows:\n",
    "#     data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, k_period, d_period)\n",
    "#     all_stoch_cols.extend(stoch_cols)\n",
    " \n",
    "# for ws in adx_windows:\n",
    "#     data_1m, adx_cols = calculate_adx(data_1m, ws)\n",
    "#     all_adx_cols.extend(adx_cols)\n",
    " \n",
    "# for ws in atr_windows:\n",
    "#     data_1m, atr_cols = calculate_atr(data_1m, ws)\n",
    "#     all_atr_cols.extend(atr_cols)\n",
    " \n",
    "# for ws in williams_windows:\n",
    "#     data_1m, will_cols = calculate_williams_r(data_1m, ws)\n",
    "#     all_will_cols.extend(will_cols)\n",
    " \n",
    "# for ws in sr_windows:\n",
    "#     data_1m, sr_col = calculate_support_resistance_numba(data_1m, window=ws)\n",
    "#     if isinstance(sr_col, list):\n",
    "#         all_sr_cols.extend(sr_col)\n",
    "#     else:\n",
    "#         all_sr_cols.append(sr_col)\n",
    "\n",
    "# test_column = ['Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
    "#                'Taker buy quote asset volume']\n",
    "\n",
    "# # 기본 피처와 사이클릭 인코딩 계산 (window size와 무관한 경우)\n",
    "# data_1m, base_feature = base_feature_fn(data_1m, alpha=100)\n",
    "# data_1m, volume_feature = calculate_volume(data_1m, window_size=240, volume_column_list=test_column)\n",
    "# data_1m, volatility_cols = calculate_volatility_features(data_1m, window=240, alpha=100)\n",
    "# data_1m, cyclic_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "\n",
    "# # 예시로 일부 test용 컬럼 정의\n",
    "# drop_column = [\n",
    "#     'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "#     'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "# ]\n",
    "\n",
    "\n",
    "# # for cloumn in test_column:\n",
    "# #     data_1m[cloumn] = log_transform(data_1m[cloumn])\n",
    "\n",
    "# # 최종 feature 컬럼을 정리합니다.\n",
    "# feature_column = (\n",
    "#     test_column +\n",
    "#     cyclic_encoding +\n",
    "#     all_ma_cols_rel +\n",
    "#     all_bb_cols_rel +\n",
    "#     all_rsi_cols +\n",
    "#     all_macd_cols +\n",
    "#     all_stoch_cols +\n",
    "#     all_adx_cols +\n",
    "#     all_will_cols +\n",
    "#     all_sr_cols +\n",
    "#     volatility_cols + \n",
    "#     volume_feature + \n",
    "#     base_feature\n",
    "# )\n",
    " \n",
    " \n",
    "# # bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = simple_fitness_fn(data_1m, 240, 60, 180)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "# bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_EMA_RSI_fitness_fn(data_1m, 20, 20, 60, 60)\n",
    "\n",
    "# # Prepare Dataset\n",
    "# data_tensor = make_dataset(\n",
    "#     data_1m,\n",
    "#     using_column=feature_column,\n",
    "#     window_size=1,\n",
    "#     entry_pos_list=bb_macd_entry_pos_list,\n",
    "#     patience_list=patience_list,\n",
    "\n",
    "# )\n",
    "# entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "# dataset_1m = []\n",
    "# skip_data_cnt = 0\n",
    "# for data in data_tensor:\n",
    "#     if type(data[0]) == np.ndarray:\n",
    "#         dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    " \n",
    "#     else:\n",
    "#         skip_data_cnt += 1\n",
    "# dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "\n",
    "# # # Avoid division by zero by replacing zero denominators with a small epsilon value\n",
    "# # epsilon = 1e-10\n",
    "# # dataset_1m[:, :, :4] = dataset_1m[:, :, :4] / (torch.mean(dataset_1m[:, :, :4], dim=0).unsqueeze(dim=1) + epsilon)\n",
    "\n",
    "# dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# data_to_save = {\n",
    "#     'dataset_1m': dataset_1m.squeeze(dim=1),\n",
    "#     'skip_data_cnt': skip_data_cnt,\n",
    "#     'entry_pos_list': entry_pos_list,\n",
    "#     'bb_macd_entry_pos_list': bb_macd_entry_pos_list,\n",
    "#     'bb_macd_entry_index_list': bb_macd_entry_index_list\n",
    "# }\n",
    "\n",
    "# with open('/root/daily/bit_5/backup_feature_data/data.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the file into separate variables\n",
    "with open('/root/daily/bit_5/backup_feature_data/data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "dataset_1m = loaded_data['dataset_1m']\n",
    "# dataset_1d = loaded_data['dataset_1d']\n",
    "skip_data_cnt = loaded_data['skip_data_cnt']\n",
    "entry_pos_list = loaded_data['entry_pos_list']\n",
    "bb_macd_entry_pos_list = loaded_data['bb_macd_entry_pos_list']\n",
    "bb_macd_entry_index_list = loaded_data['bb_macd_entry_index_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_skip_data_cnt = int(len(dataset_1m)*0.6) + skip_data_cnt\n",
    "test_skip_data_cnt = int(len(dataset_1m)*0.8) + skip_data_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 197370000\n",
      "generation  0: \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=30000, weight of size [1920000, 54, 1], expected input[128, 1440000, 1] to have 1620000 channels, but got 1440000 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# mutation = AddNormalMutation(mut_prob=0.1)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m evolution \u001b[38;5;241m=\u001b[39m Evolution(\n\u001b[1;32m     48\u001b[0m     prescriptor\u001b[38;5;241m=\u001b[39mprescriptor,\n\u001b[1;32m     49\u001b[0m     selection\u001b[38;5;241m=\u001b[39mselection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     group_size\u001b[38;5;241m=\u001b[39mgroup\n\u001b[1;32m     53\u001b[0m )\n\u001b[0;32m---> 55\u001b[0m best_chromosomes, best_profit \u001b[38;5;241m=\u001b[39m \u001b[43mgeneration_valid\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_1m\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_1m\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_1m\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_1m\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# dataset_1d=dataset_1d,\u001b[39;49;00m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprescriptor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprescriptor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_data_cnt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_data_cnt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_skip_data_cnt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_skip_data_cnt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_skip_data_cnt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_skip_data_cnt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchromosomes_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchromosomes_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43melite_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melite_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprofit_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofit_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_index_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbb_macd_entry_index_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentry_pos_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mentry_pos_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_profit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_profit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_chromosomes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbest_chromosomes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstart_gen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/daily/bit_5/train_functions_bi_cul.py:670\u001b[0m, in \u001b[0;36mgeneration_valid\u001b[0;34m(data_1m, dataset_1m, prescriptor, evolution, skip_data_cnt, valid_skip_data_cnt, test_skip_data_cnt, chromosomes_size, window_size, gen_loop, best_size, elite_size, profit_init, entry_index_list, entry_pos_list, best_profit, best_chromosomes, start_gen, device, warming_step)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gen_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_gen, gen_loop):\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgen_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 670\u001b[0m     probs \u001b[38;5;241m=\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_1m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprescriptor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;66;03m# probs = torch.concat(probs, dim=1)\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m fitness_fn(\n\u001b[1;32m    674\u001b[0m         prescriptor\u001b[38;5;241m=\u001b[39mprescriptor,\n\u001b[1;32m    675\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata_1m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    688\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    689\u001b[0m     )\n",
      "File \u001b[0;32m~/daily/bit_5/train_functions_bi_cul.py:151\u001b[0m, in \u001b[0;36minference\u001b[0;34m(scaled_tensor, model, device)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# 최종 결과 텐서 크기를 미리 계산 (예: (feature_dim, total_seq_len, other_dim))\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# 예시로 첫 배치에서 logit shape을 확인\u001b[39;00m\n\u001b[1;32m    150\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader))\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 151\u001b[0m sample_logit \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mhalf()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    152\u001b[0m total_seq_len \u001b[38;5;241m=\u001b[39m sample_logit\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# 최종 텐서 shape : (feature_dim, total_seq_len, other_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/daily/bit_5/Prescriptor/prescriptor.py:151\u001b[0m, in \u001b[0;36mPrescriptor.base_forward\u001b[0;34m(self, small_x)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbase_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, small_x):\n\u001b[0;32m--> 151\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/daily/bit_5/Prescriptor/prescriptor.py:118\u001b[0m, in \u001b[0;36mBaseConvFully.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    115\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_size, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape: [100, 1560, 1]\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# 3. Task 1: 연속된 Conv1d와 GELU 활성화 레이어를 통과합니다.\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# 4. 최종 MLP layer를 통과합니다.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_final(x1)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=30000, weight of size [1920000, 54, 1], expected input[128, 1440000, 1] to have 1620000 channels, but got 1440000 channels instead"
     ]
    }
   ],
   "source": [
    "# Evolution Setup\n",
    "# 전역적으로 기울기 계산 비활성화\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "chromosomes_size=30000\n",
    "window_size=240\n",
    "EPOCH = 5\n",
    "gen_loop=50\n",
    "best_size=30000\n",
    "elite_size=6000\n",
    "profit_init=1\n",
    "device = 'cuda:1'\n",
    "group = 30000\n",
    "start_gen = 0\n",
    "best_profit = None\n",
    "best_chromosomes = None\n",
    "\n",
    "prescriptor = Prescriptor(input_dim=54, \n",
    "                fc_hidden_size=16, \n",
    "                output_dim=8, \n",
    "                after_input_dim=11, \n",
    "                after_hidden_dim=16, \n",
    "                after_output_dim=5, \n",
    "                num_blocks=group).to(device).eval()\n",
    "\n",
    "# if i == 1:\n",
    "#     start_gen=0\n",
    "\n",
    "# if i == 0:\n",
    "#     prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "selection = RouletteSelection(elite_num=6000, parents_num=12000, minimize=False)\n",
    "# selection = ParetoLexsortSelection(elite_num=2000, parents_num=4000,\n",
    "#                                     priority=[], prior_ratio= [],\n",
    "#                                     prob_method= 'softmax',minimize=False)\n",
    "# crossover = DifferentialEvolutionOperator()\n",
    "# crossover = UniformCrossover(num_parents=4)\n",
    "# crossover = CenDE_DOBLOperator()\n",
    "mutation = ChainMutation([RandomValueMutation(mut_prob=0.05), AddUniformMutation(mut_prob=0.1)])\n",
    "# crossover = UniformCrossover(num_parents=1)\n",
    "crossover = DifferentialEvolutionOperator()\n",
    "# mutation = AddNormalMutation(mut_prob=0.1)\n",
    "evolution = Evolution(\n",
    "    prescriptor=prescriptor,\n",
    "    selection=selection,\n",
    "    crossover=crossover,\n",
    "    mutation=mutation,\n",
    "    group_size=group\n",
    ")\n",
    "\n",
    "best_chromosomes, best_profit = generation_valid(\n",
    "    data_1m=data_1m,\n",
    "    dataset_1m=dataset_1m,\n",
    "    # dataset_1d=dataset_1d,\n",
    "    prescriptor=prescriptor,\n",
    "    evolution=evolution,\n",
    "    skip_data_cnt=skip_data_cnt,\n",
    "    valid_skip_data_cnt=valid_skip_data_cnt,\n",
    "    test_skip_data_cnt=test_skip_data_cnt,\n",
    "    chromosomes_size=chromosomes_size,\n",
    "    window_size=window_size,\n",
    "    gen_loop=gen_loop,\n",
    "    best_size=best_size,\n",
    "    elite_size=elite_size,\n",
    "    profit_init=profit_init,\n",
    "    entry_index_list=bb_macd_entry_index_list,\n",
    "    entry_pos_list=entry_pos_list,\n",
    "    best_profit=best_profit,\n",
    "    best_chromosomes=best_chromosomes,\n",
    "    start_gen=start_gen,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
