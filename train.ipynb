{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations_2 import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, cyclic_encode_fn, calculate_support_resistance_numba\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn, simple_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions_total_train import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor, CryptoModelTCN\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator, CenDE_DOBLOperator, SkipCrossover\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_1m = load_data_1m('/root/daily/bit/data/1min_bitusdt_test.pkl')\n",
    "# data_1m = data_1m.iloc[:200000]\n",
    "\n",
    "# Resample data to 1D\n",
    "data_1d = resample_data(data_1m, '1D')\n",
    "# data_1d['Close time'] = data_1d.index\n",
    "# data_1d = data_1d.reset_index(drop=True)\n",
    "\n",
    "# # Apply Feature Calculations\n",
    "# # For 1D Data\n",
    "# data_1d, ma_cols_1d, ma_cols_rel_1d = calculate_MA_data(data_1d, 60, 'EMA', '_1d')\n",
    "# data_1d, bb_cols_1d, bb_cols_rel_1d = calculate_ema_bollinger_bands(data_1d, 60, extra_str='_1d')\n",
    "# data_1d, rsi_cols_1d = calculate_rsi(data_1d, window=20, extra_str='_1d')\n",
    "# data_1d, macd_cols_1d = calculate_macd(data_1d, 20, 120, 60, extra_str='_1d')\n",
    "# data_1d, stoch_cols_1d = calculate_stochastic_oscillator(data_1d, 60, 20, extra_str='_1d')\n",
    "# data_1d, adx_cols_1d = calculate_adx(data_1d, 60, extra_str='_1d')\n",
    "# data_1d, atr_cols_1d = calculate_atr(data_1d, 60, extra_str='_1d')\n",
    "# data_1d, obv_cols_1d = calculate_obv(data_1d, extra_str='_1d')\n",
    "# data_1d, will_cols_1d = calculate_williams_r(data_1d, 60, extra_str='_1d')\n",
    "# data_1d, sr_col_1d = calculate_support_resistance_numba(data_1d, window=60, extra_str='_1d')\n",
    "# data_1d, base_feature_1d = base_feature_fn(data_1d, extra_str='_1d', alpha=10)\n",
    "# data_1d, cyclice_encoding_1d = cyclic_encode_fn(data_1d, 'Close time', 'day_of_week')\n",
    "\n",
    "# # For 1M Data\n",
    "# data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, 240, 'EMA')\n",
    "# data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, 240)\n",
    "# data_1m, macd_cols = calculate_macd(data_1m, 60, 600, 240)\n",
    "# data_1m, rsi_cols = calculate_rsi(data_1m, window=60)\n",
    "# data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, 240, 60)\n",
    "# data_1m, adx_cols = calculate_adx(data_1m, 240)\n",
    "# data_1m, atr_cols = calculate_atr(data_1m, 240)\n",
    "# data_1m, obv_cols = calculate_obv(data_1m)\n",
    "# data_1m, will_cols = calculate_williams_r(data_1m, 240)\n",
    "# data_1m, sr_col = calculate_support_resistance_numba(data_1m, window=240)\n",
    "# data_1m, base_feature = base_feature_fn(data_1m, alpha=100)\n",
    "# data_1m, cyclice_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "# data_1m, short_ma_cols, short_ma_cols_rel = calculate_MA_data(data_1m, 60, 'EMA')\n",
    "# data_1m, long_ma_cols, long_ma_cols_rel = calculate_MA_data(data_1m, 180, 'EMA')\n",
    "\n",
    "# data_1m, short_ma_cols, short_ma_cols_rel = calculate_MA_data(data_1m, 20, 'EMA')\n",
    "# data_1m, long_ma_cols, long_ma_cols_rel = calculate_MA_data(data_1m, 60, 'EMA')\n",
    "# data_1m, _, _ = calculate_ema_bollinger_bands(data_1m, 60)\n",
    "\n",
    "# # Prepare Feature Columns\n",
    "# drop_column = [\n",
    "#     'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "#     'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "# ]\n",
    "\n",
    "# test_column = ['Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
    "#                'Taker buy quote asset volume']\n",
    "# # feature_column = (\n",
    "# #     test_column + cyclice_encoding + ma_cols_rel + bb_cols_rel + rsi_cols + macd_cols + stoch_cols +\n",
    "# #     adx_cols + will_cols + sr_col + base_feature  # Excluding obv and atr\n",
    "# # )\n",
    "\n",
    "# feature_column = (\n",
    "#     test_column + cyclice_encoding +  base_feature  # Excluding obv and atr\n",
    "# )\n",
    "# feature_column_1d = (\n",
    "#     test_column + cyclice_encoding_1d + ma_cols_rel_1d + bb_cols_rel_1d + rsi_cols_1d + macd_cols_1d + stoch_cols_1d +\n",
    "#     adx_cols_1d + will_cols_1d + sr_col_1d + base_feature_1d\n",
    "# )\n",
    "\n",
    "\n",
    "# # bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "# bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 240, 60, 180)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = simple_fitness_fn(data_1m, 240, 60, 180)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "\n",
    "# # Prepare Dataset\n",
    "# data_tensor = make_dataset(\n",
    "#     data_1m, data_1d,\n",
    "#     using_column=feature_column, using_column_1d=feature_column_1d,\n",
    "#     window_size=240, window_size_1d=60,\n",
    "#     entry_pos_list=bb_macd_entry_pos_list, patience_list=patience_list,\n",
    "#     use_1d_data=True\n",
    "# )\n",
    "# entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "# dataset_1m = []\n",
    "# dataset_1d = []\n",
    "# skip_data_cnt = 0\n",
    "# for data in data_tensor:\n",
    "#     if len(data[0]) == 240 and len(data[1]) == 60:\n",
    "#         dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    "#         dataset_1d.append(torch.from_numpy(data[1]).unsqueeze(dim=0))\n",
    "#     else:\n",
    "#         skip_data_cnt += 1\n",
    "# dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "# dataset_1d = torch.cat(dataset_1d, dim=0)\n",
    "\n",
    "# # Avoid division by zero by replacing zero denominators with a small epsilon value\n",
    "# epsilon = 1e-10\n",
    "# dataset_1m[:, :, :4] = dataset_1m[:, :, :4] / (torch.mean(dataset_1m[:, :, :4], dim=1).unsqueeze(dim=1) + epsilon)\n",
    "# dataset_1d[:, :, :4] = dataset_1d[:, :, :4] / (torch.mean(dataset_1d[:, :, :4], dim=1).unsqueeze(dim=1) + epsilon)\n",
    "\n",
    "# dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "# dataset_1d = replace_nan_with_zero(dataset_1d)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# data_to_save = {\n",
    "#     'dataset_1m': dataset_1m,\n",
    "#     'dataset_1d': dataset_1d,\n",
    "#     'skip_data_cnt': skip_data_cnt,\n",
    "#     'entry_pos_list': entry_pos_list,\n",
    "#     'bb_macd_entry_pos_list': bb_macd_entry_pos_list,\n",
    "#     'bb_macd_entry_index_list': bb_macd_entry_index_list\n",
    "# }\n",
    "\n",
    "# with open('/root/daily/bit_4/backup_feature_data/data.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_to_save, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the file into separate variables\n",
    "with open('/root/daily/bit_4/backup_feature_data/data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "dataset_1m = loaded_data['dataset_1m']\n",
    "dataset_1d = loaded_data['dataset_1d']\n",
    "skip_data_cnt = loaded_data['skip_data_cnt']\n",
    "entry_pos_list = loaded_data['entry_pos_list']\n",
    "bb_macd_entry_pos_list = loaded_data['bb_macd_entry_pos_list']\n",
    "bb_macd_entry_index_list = loaded_data['bb_macd_entry_index_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_skip_data_cnt = int(len(dataset_1m)*0.6) + skip_data_cnt\n",
    "test_skip_data_cnt = int(len(dataset_1m)*0.8) + skip_data_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 341310000\n",
      "generation  12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:55<00:00, 16.17s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.18s/it]\n",
      " 80%|████████  | 36216/45022 [07:30<01:49, 80.41it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.22s/it]\n",
      " 80%|████████  | 36216/45022 [07:31<01:49, 80.17it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.27s/it]\n",
      " 80%|████████  | 36216/45022 [07:35<01:50, 79.52it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.27s/it]\n",
      " 80%|████████  | 36216/45022 [07:34<01:50, 79.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.20s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.26s/it]\n",
      " 80%|████████  | 36216/45022 [07:38<01:51, 78.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.19s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.23s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 80.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.27s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.77it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:55<00:00, 16.17s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 79.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.29s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.21s/it]\n",
      " 80%|████████  | 36216/45022 [07:30<01:49, 80.45it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.29s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 80.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.20s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:49, 80.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.29s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.22s/it]\n",
      " 80%|████████  | 36216/45022 [07:36<01:51, 79.31it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:36<01:50, 79.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  31: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.21s/it]\n",
      " 80%|████████  | 36216/45022 [07:38<01:51, 78.99it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  32: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.26s/it]\n",
      " 80%|████████  | 36216/45022 [07:37<01:51, 79.09it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:55<00:00, 16.17s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:49, 80.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  34: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.27s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  35: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.20s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 80.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  36: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:31<01:49, 80.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  37: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.20s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 79.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  38: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  39: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.22s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  40: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:34<01:50, 79.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  41: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.22s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  42: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.31s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  43: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.21s/it]\n",
      " 80%|████████  | 36216/45022 [07:30<01:49, 80.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  44: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.29s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:49, 80.08it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  45: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.21s/it]\n",
      " 80%|████████  | 36216/45022 [07:30<01:49, 80.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  46: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.30s/it]\n",
      " 80%|████████  | 36216/45022 [07:33<01:50, 79.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  47: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.20s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:49, 80.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  48: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:31<01:49, 80.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  49: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:56<00:00, 16.21s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 80.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 341310000\n",
      "generation  0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.27s/it]\n",
      " 80%|████████  | 36216/45022 [04:40<01:08, 129.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:57<00:00, 16.26s/it]\n",
      " 80%|████████  | 36216/45022 [07:32<01:50, 80.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 22/22 [05:58<00:00, 16.28s/it]\n",
      " 80%|████████  | 36216/45022 [07:34<01:50, 79.64it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evolution Setup\n",
    "# 전역적으로 기울기 계산 비활성화\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "chromosomes_size=10000\n",
    "window_size=240\n",
    "EPOCH = 3\n",
    "gen_loop=50\n",
    "best_size=10000\n",
    "elite_size=2000\n",
    "profit_init=1\n",
    "device = 'cuda:1'\n",
    "group = 10000\n",
    "start_gen = 0\n",
    "best_profit = None\n",
    "best_chromosomes = None\n",
    "\n",
    "state_dict_path = '/root/daily/bit_4/generation/generation_11.pt'\n",
    "if os.path.exists(state_dict_path):\n",
    "    state_dict = torch.load(state_dict_path)\n",
    "    start_gen = state_dict['generation'] + 1\n",
    "    best_profit = state_dict['best_profit']\n",
    "    best_chromosomes = state_dict['best_chromosomes']\n",
    "    # prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "for i in range(EPOCH):\n",
    "    prescriptor = Prescriptor(\n",
    "        basic_block=CryptoModelTCN, \n",
    "        small_input_dim=14, \n",
    "        large_input_dim=25,\n",
    "        fc_hidden_size=24,\n",
    "        small_lstm_hidden_dim=24,\n",
    "        large_lstm_hidden_dim=24,\n",
    "        output_dim=16, \n",
    "        after_input_dim=19, \n",
    "        after_hidden_dim=8, \n",
    "        after_output_dim=5, \n",
    "        num_blocks=group,\n",
    "    ).to(device).eval()\n",
    "\n",
    "    if i == 1:\n",
    "        start_gen=0\n",
    "\n",
    "    if i == 0:\n",
    "        prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "    total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "    print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "    selection = RouletteSelection(elite_num=2000, parents_num=4000, minimize=False)\n",
    "    # selection = ParetoLexsortSelection(elite_num=2000, parents_num=4000,\n",
    "    #                                     priority=[], prior_ratio= [],\n",
    "    #                                     prob_method= 'softmax',minimize=False)\n",
    "    # crossover = DifferentialEvolutionOperator()\n",
    "    # crossover = UniformCrossover(num_parents=4)\n",
    "    # crossover = CenDE_DOBLOperator()\n",
    "    mutation = ChainMutation([RandomValueMutation(mut_prob=0.05), AddUniformMutation(mut_prob=0.1)])\n",
    "    crossover = UniformCrossover(num_parents=1)\n",
    "    # mutation = AddNormalMutation(mut_prob=0.1)\n",
    "    evolution = Evolution(\n",
    "        prescriptor=prescriptor,\n",
    "        selection=selection,\n",
    "        crossover=crossover,\n",
    "        mutation=mutation\n",
    "    )\n",
    "\n",
    "    best_chromosomes, best_profit = generation_valid(\n",
    "        data_1m=data_1m,\n",
    "        dataset_1m=dataset_1m,\n",
    "        dataset_1d=dataset_1d,\n",
    "        prescriptor=prescriptor,\n",
    "        evolution=evolution,\n",
    "        skip_data_cnt=skip_data_cnt,\n",
    "        valid_skip_data_cnt=test_skip_data_cnt,\n",
    "        test_skip_data_cnt=test_skip_data_cnt,\n",
    "        chromosomes_size=chromosomes_size,\n",
    "        window_size=window_size,\n",
    "        gen_loop=gen_loop,\n",
    "        best_size=best_size,\n",
    "        elite_size=elite_size,\n",
    "        profit_init=profit_init,\n",
    "        entry_index_list=bb_macd_entry_index_list,\n",
    "        entry_pos_list=entry_pos_list,\n",
    "        best_profit=best_profit,\n",
    "        best_chromosomes=best_chromosomes,\n",
    "        start_gen=start_gen,\n",
    "        device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
