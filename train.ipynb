{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations_2 import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr, calculate_volume,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, calculate_volatility_features, cyclic_encode_fn, calculate_support_resistance_numba, log_transform\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn, simple_fitness_fn, BB_MACD_EMA_RSI_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions_bi_cul import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor, CryptoModelTCN\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator, CenDE_DOBLOperator, SkipCrossover\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data_1m = load_data_1m('/root/daily/bit/data/1min_ethusdt.pkl')\n",
    "# # data_1m = data_1m.iloc[:200000]\n",
    "\n",
    "# # 각 지표별 window 설정 및 계산\n",
    "# ma_windows = [5, 20, 60]\n",
    "# bb_windows = [5, 20, 60]\n",
    "# macd_windows = [(60, 600, 240), (30, 300, 120), (6, 13, 4)]\n",
    "# rsi_windows = [7, 20, 60]\n",
    "# stoch_windows = [(240, 60), (120, 30), (9, 3)]\n",
    "# adx_windows = [60, 20, 7]\n",
    "# atr_windows = [60, 20, 7]\n",
    "# williams_windows = [60, 20, 7]\n",
    "# sr_windows =  [120, 60, 20]\n",
    "\n",
    "# all_ma_cols, all_ma_cols_rel = [], []\n",
    "# all_bb_cols, all_bb_cols_rel = [], []\n",
    "# all_macd_cols = []\n",
    "# all_rsi_cols = []\n",
    "# all_stoch_cols = []\n",
    "# all_adx_cols = []\n",
    "# all_atr_cols = []\n",
    "# all_will_cols = []\n",
    "# all_sr_cols = []\n",
    " \n",
    "# for ws in ma_windows:\n",
    "#     data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, ws, 'MA')\n",
    "#     all_ma_cols.extend(ma_cols)\n",
    "#     all_ma_cols_rel.extend(ma_cols_rel)\n",
    " \n",
    "# data_1m, _, __ = calculate_MA_data(data_1m, 180, 'MA')\n",
    "# for ws in bb_windows:\n",
    "#     data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, ws)\n",
    "#     all_bb_cols.extend(bb_cols)\n",
    "#     all_bb_cols_rel.extend(bb_cols_rel)\n",
    " \n",
    "# for short_period, long_period, signal_period in macd_windows:\n",
    "#     data_1m, macd_cols = calculate_macd(data_1m, short_period, long_period, signal_period)\n",
    "#     all_macd_cols.extend(macd_cols)\n",
    " \n",
    "# for ws in rsi_windows:\n",
    "#     data_1m, rsi_cols = calculate_rsi(data_1m, window=ws)\n",
    "#     all_rsi_cols.extend(rsi_cols)\n",
    " \n",
    "# for k_period, d_period in stoch_windows:\n",
    "#     data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, k_period, d_period)\n",
    "#     all_stoch_cols.extend(stoch_cols)\n",
    " \n",
    "# for ws in adx_windows:\n",
    "#     data_1m, adx_cols = calculate_adx(data_1m, ws)\n",
    "#     all_adx_cols.extend(adx_cols)\n",
    " \n",
    "# for ws in atr_windows:\n",
    "#     data_1m, atr_cols = calculate_atr(data_1m, ws)\n",
    "#     all_atr_cols.extend(atr_cols)\n",
    " \n",
    "# for ws in williams_windows:\n",
    "#     data_1m, will_cols = calculate_williams_r(data_1m, ws)\n",
    "#     all_will_cols.extend(will_cols)\n",
    " \n",
    "# for ws in sr_windows:\n",
    "#     data_1m, sr_col = calculate_support_resistance_numba(data_1m, window=ws)\n",
    "#     if isinstance(sr_col, list):\n",
    "#         all_sr_cols.extend(sr_col)\n",
    "#     else:\n",
    "#         all_sr_cols.append(sr_col)\n",
    "\n",
    "# test_column = ['Quote asset volume', 'Number of trades', 'Taker buy base asset volume',\n",
    "#                'Taker buy quote asset volume']\n",
    "\n",
    "# # 기본 피처와 사이클릭 인코딩 계산 (window size와 무관한 경우)\n",
    "# data_1m, base_feature = base_feature_fn(data_1m, alpha=100)\n",
    "# data_1m, volume_feature = calculate_volume(data_1m, window_size=240, volume_column_list=test_column)\n",
    "# data_1m, volatility_cols = calculate_volatility_features(data_1m, window=240, alpha=100)\n",
    "# data_1m, cyclic_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "\n",
    "# # 예시로 일부 test용 컬럼 정의\n",
    "# drop_column = [\n",
    "#     'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "#     'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "# ]\n",
    "\n",
    "\n",
    "# # for cloumn in test_column:\n",
    "# #     data_1m[cloumn] = log_transform(data_1m[cloumn])\n",
    "\n",
    "# # 최종 feature 컬럼을 정리합니다.\n",
    "# feature_column = (\n",
    "#     test_column +\n",
    "#     cyclic_encoding +\n",
    "#     all_ma_cols_rel +\n",
    "#     all_bb_cols_rel +\n",
    "#     all_rsi_cols +\n",
    "#     all_macd_cols +\n",
    "#     all_stoch_cols +\n",
    "#     all_adx_cols +\n",
    "#     all_will_cols +\n",
    "#     all_sr_cols +\n",
    "#     volatility_cols + \n",
    "#     volume_feature + \n",
    "#     base_feature\n",
    "# )\n",
    " \n",
    " \n",
    "# # bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = simple_fitness_fn(data_1m, 240, 60, 180)\n",
    "# # bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 60, 20, 60)\n",
    "# bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_EMA_RSI_fitness_fn(data_1m, 60, 20, 60, 180)\n",
    "\n",
    "# # Prepare Dataset\n",
    "# data_tensor = make_dataset(\n",
    "#     data_1m,\n",
    "#     using_column=feature_column,\n",
    "#     window_size=1,\n",
    "#     entry_pos_list=bb_macd_entry_pos_list,\n",
    "#     patience_list=patience_list,\n",
    "\n",
    "# )\n",
    "# entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "# dataset_1m = []\n",
    "# skip_data_cnt = 0\n",
    "# for data in data_tensor:\n",
    "#     if type(data[0]) == np.ndarray:\n",
    "#         dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    " \n",
    "#     else:\n",
    "#         skip_data_cnt += 1\n",
    "# dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "\n",
    "# # # Avoid division by zero by replacing zero denominators with a small epsilon value\n",
    "# # epsilon = 1e-10\n",
    "# # dataset_1m[:, :, :4] = dataset_1m[:, :, :4] / (torch.mean(dataset_1m[:, :, :4], dim=0).unsqueeze(dim=1) + epsilon)\n",
    "\n",
    "# dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# data_to_save = {\n",
    "#     'dataset_1m': dataset_1m.squeeze(dim=1),\n",
    "#     'skip_data_cnt': skip_data_cnt,\n",
    "#     'entry_pos_list': entry_pos_list,\n",
    "#     'bb_macd_entry_pos_list': bb_macd_entry_pos_list,\n",
    "#     'bb_macd_entry_index_list': bb_macd_entry_index_list\n",
    "# }\n",
    "\n",
    "# with open('/root/daily/bit_5/backup_feature_data/data.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_to_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the file into separate variables\n",
    "with open('/root/daily/bit_5/backup_feature_data/data.pkl', 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "\n",
    "dataset_1m = loaded_data['dataset_1m']\n",
    "# dataset_1d = loaded_data['dataset_1d']\n",
    "skip_data_cnt = loaded_data['skip_data_cnt']\n",
    "entry_pos_list = loaded_data['entry_pos_list']\n",
    "bb_macd_entry_pos_list = loaded_data['bb_macd_entry_pos_list']\n",
    "bb_macd_entry_index_list = loaded_data['bb_macd_entry_index_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90609, 54])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_skip_data_cnt = int(len(dataset_1m)*0.6) + skip_data_cnt\n",
    "test_skip_data_cnt = int(len(dataset_1m)*0.8) + skip_data_cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 197370000\n",
      "generation  0: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:42<00:00,  4.36it/s]\n",
      " 60%|██████    | 54472/90716 [12:25<08:16, 73.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:18<00:00,  5.10it/s]\n",
      " 60%|██████    | 54472/90716 [12:24<08:15, 73.13it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  2: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.09it/s]\n",
      " 60%|██████    | 54472/90716 [12:09<08:05, 74.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:18<00:00,  5.10it/s]\n",
      " 60%|██████    | 54472/90716 [12:21<08:13, 73.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  4: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [12:15<08:09, 74.04it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  5: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [12:02<08:00, 75.42it/s]  \n",
      " 80%|████████  | 72594/90716 [03:01<00:45, 400.20it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  6: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:50<07:52, 76.66it/s]  \n",
      " 80%|████████  | 72594/90716 [02:51<00:42, 423.76it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  7: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.08it/s]\n",
      " 60%|██████    | 54472/90716 [11:36<07:43, 78.23it/s] \n",
      " 80%|████████  | 72594/90716 [02:45<00:41, 438.70it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  8: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.08it/s]\n",
      " 60%|██████    | 54472/90716 [11:22<07:34, 79.76it/s] \n",
      " 80%|████████  | 72594/90716 [02:43<00:40, 443.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  9: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:24<07:35, 79.62it/s]  \n",
      " 80%|████████  | 72594/90716 [02:44<00:40, 442.15it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  10: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [11:15<07:29, 80.65it/s]\n",
      " 80%|████████  | 72594/90716 [02:42<00:40, 445.88it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  11: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:11<07:26, 81.18it/s]  \n",
      " 80%|████████  | 72594/90716 [02:40<00:40, 451.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  12: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.08it/s]\n",
      " 60%|██████    | 54472/90716 [10:56<07:16, 82.94it/s] \n",
      " 80%|████████  | 72594/90716 [02:40<00:40, 452.88it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  13: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:11<07:26, 81.11it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 448.93it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  14: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:12<07:27, 81.01it/s] \n",
      " 80%|████████  | 72594/90716 [02:40<00:39, 453.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  15: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:01<07:20, 82.33it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 454.38it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  16: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:01<07:19, 82.40it/s] \n",
      " 80%|████████  | 72594/90716 [02:40<00:40, 452.46it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  17: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:12<07:27, 81.05it/s]  \n",
      " 80%|████████  | 72594/90716 [02:42<00:40, 447.80it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  18: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:03<07:21, 82.11it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 449.36it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  19: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [10:54<07:15, 83.18it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 456.47it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  20: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:06<07:23, 81.74it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 449.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  21: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:18<07:31, 80.33it/s]  \n",
      " 80%|████████  | 72594/90716 [02:42<00:40, 447.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  22: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:12<07:27, 81.04it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 449.68it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  23: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.08it/s]\n",
      " 60%|██████    | 54472/90716 [11:00<07:19, 82.52it/s] \n",
      " 80%|████████  | 72594/90716 [02:40<00:39, 453.69it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  24: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:03<07:21, 82.10it/s] \n",
      " 80%|████████  | 72594/90716 [02:40<00:39, 453.47it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  25: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:03<07:21, 82.11it/s]\n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 454.39it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  26: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:08<07:24, 81.54it/s]  \n",
      " 80%|████████  | 72594/90716 [02:40<00:39, 453.55it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  27: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [11:05<07:23, 81.81it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 450.86it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  28: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [11:00<07:19, 82.43it/s]\n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 456.34it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  29: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:02<07:20, 82.19it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 455.55it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  30: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [11:00<07:19, 82.46it/s]\n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 455.27it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  31: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [11:09<07:25, 81.33it/s]\n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 454.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  32: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.08it/s]\n",
      " 60%|██████    | 54472/90716 [11:12<07:27, 81.03it/s]  \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 454.67it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  33: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:02<07:20, 82.24it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 455.76it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  34: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.04it/s]\n",
      " 60%|██████    | 54472/90716 [11:04<07:22, 81.96it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 453.82it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  35: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.04it/s]\n",
      " 60%|██████    | 54472/90716 [11:02<07:20, 82.23it/s]\n",
      " 80%|████████  | 72594/90716 [02:38<00:39, 456.68it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  36: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.06it/s]\n",
      " 60%|██████    | 54472/90716 [10:57<07:17, 82.84it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 454.85it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  37: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [10:58<07:17, 82.75it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 450.23it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  38: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.03it/s]\n",
      " 60%|██████    | 54472/90716 [11:06<07:23, 81.79it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 449.86it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  39: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.03it/s]\n",
      " 60%|██████    | 54472/90716 [11:03<07:21, 82.14it/s] \n",
      " 80%|████████  | 72594/90716 [02:38<00:39, 457.43it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  40: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.04it/s]\n",
      " 60%|██████    | 54472/90716 [11:09<07:25, 81.34it/s]  \n",
      " 80%|████████  | 72594/90716 [02:40<00:39, 453.68it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  41: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:04<07:22, 81.98it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 455.72it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  42: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:19<00:00,  5.07it/s]\n",
      " 60%|██████    | 54472/90716 [11:05<07:22, 81.88it/s] \n",
      " 80%|████████  | 72594/90716 [02:41<00:40, 449.30it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  43: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.04it/s]\n",
      " 60%|██████    | 54472/90716 [10:59<07:19, 82.56it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 456.05it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  44: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.04it/s]\n",
      " 60%|██████    | 54472/90716 [11:05<07:22, 81.85it/s]\n",
      " 80%|████████  | 72594/90716 [02:40<00:40, 452.58it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  45: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [11:03<07:21, 82.14it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 453.77it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  46: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.03it/s]\n",
      " 60%|██████    | 54472/90716 [10:59<07:19, 82.55it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 456.38it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  47: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:20<00:00,  5.05it/s]\n",
      " 60%|██████    | 54472/90716 [10:55<07:16, 83.09it/s] \n",
      " 80%|████████  | 72594/90716 [02:39<00:39, 453.95it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  48: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:21<00:00,  5.02it/s]\n",
      " 60%|██████    | 54472/90716 [11:06<07:23, 81.78it/s] \n",
      " 80%|████████  | 72594/90716 [02:42<00:40, 447.81it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation  49: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference Progress: 100%|██████████| 708/708 [02:21<00:00,  5.01it/s]\n",
      " 60%|██████    | 54472/90716 [11:09<07:25, 81.30it/s]\n",
      " 80%|████████  | 72594/90716 [02:53<00:43, 417.77it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Evolution Setup\n",
    "# 전역적으로 기울기 계산 비활성화\n",
    "torch.set_grad_enabled(False)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "chromosomes_size=30000\n",
    "window_size=240\n",
    "EPOCH = 5\n",
    "gen_loop=50\n",
    "best_size=30000\n",
    "elite_size=6000\n",
    "profit_init=1\n",
    "device = 'cuda:1'\n",
    "group = 30000\n",
    "start_gen = 0\n",
    "best_profit = None\n",
    "best_chromosomes = None\n",
    "\n",
    "prescriptor = Prescriptor(input_dim=54, \n",
    "                fc_hidden_size=16, \n",
    "                output_dim=8, \n",
    "                after_input_dim=11, \n",
    "                after_hidden_dim=16, \n",
    "                after_output_dim=5, \n",
    "                num_blocks=group).to(device).eval()\n",
    "\n",
    "# if i == 1:\n",
    "#     start_gen=0\n",
    "\n",
    "# if i == 0:\n",
    "#     prescriptor.load_state_dict(state_dict['prescriptor_state_dict'],strict=True)\n",
    "\n",
    "total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "selection = RouletteSelection(elite_num=6000, parents_num=12000, minimize=False)\n",
    "# selection = ParetoLexsortSelection(elite_num=2000, parents_num=4000,\n",
    "#                                     priority=[], prior_ratio= [],\n",
    "#                                     prob_method= 'softmax',minimize=False)\n",
    "# crossover = DifferentialEvolutionOperator()\n",
    "# crossover = UniformCrossover(num_parents=4)\n",
    "# crossover = CenDE_DOBLOperator()\n",
    "mutation = ChainMutation([RandomValueMutation(mut_prob=0.05), AddUniformMutation(mut_prob=0.1)])\n",
    "# crossover = UniformCrossover(num_parents=1)\n",
    "crossover = DifferentialEvolutionOperator()\n",
    "# mutation = AddNormalMutation(mut_prob=0.1)\n",
    "evolution = Evolution(\n",
    "    prescriptor=prescriptor,\n",
    "    selection=selection,\n",
    "    crossover=crossover,\n",
    "    mutation=mutation,\n",
    "    group_size=group\n",
    ")\n",
    "\n",
    "best_chromosomes, best_profit = generation_valid(\n",
    "    data_1m=data_1m,\n",
    "    dataset_1m=dataset_1m,\n",
    "    # dataset_1d=dataset_1d,\n",
    "    prescriptor=prescriptor,\n",
    "    evolution=evolution,\n",
    "    skip_data_cnt=skip_data_cnt,\n",
    "    valid_skip_data_cnt=valid_skip_data_cnt,\n",
    "    test_skip_data_cnt=test_skip_data_cnt,\n",
    "    chromosomes_size=chromosomes_size,\n",
    "    window_size=window_size,\n",
    "    gen_loop=gen_loop,\n",
    "    best_size=best_size,\n",
    "    elite_size=elite_size,\n",
    "    profit_init=profit_init,\n",
    "    entry_index_list=bb_macd_entry_index_list,\n",
    "    entry_pos_list=entry_pos_list,\n",
    "    best_profit=best_profit,\n",
    "    best_chromosomes=best_chromosomes,\n",
    "    start_gen=start_gen,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
