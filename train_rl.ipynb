{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from data_loader import load_data_1m\n",
    "from feature_calculations import (\n",
    "    resample_data, calculate_MA_data, calculate_ema_bollinger_bands, calculate_rsi,\n",
    "    calculate_macd, calculate_stochastic_oscillator, calculate_adx, calculate_atr,\n",
    "    calculate_obv, calculate_williams_r, base_feature_fn, cyclic_encode_fn, log_transform\n",
    ")\n",
    "from strategies import BB_fitness_fn, BB_MACD_fitness_fn\n",
    "from dataset import make_dataset, replace_nan_with_zero\n",
    "from train_functions_rl import inference, fitness_fn, generation_valid, generation_test\n",
    "\n",
    "from Prescriptor import Prescriptor, ChromosomeSelectorModel\n",
    "from Evolution.crossover import UniformCrossover, WeightedSumCrossover, DifferentialEvolutionOperator, CenDE_DOBLOperator\n",
    "from Evolution.mutation import MultiplyNormalMutation, MultiplyUniformMutation, AddNormalMutation, AddUniformMutation, ChainMutation, FlipSignMutation\n",
    "from Evolution.mutation import RandomValueMutation\n",
    "from Evolution.selection import RouletteSelection, TournamentSelection, ParetoLexsortSelection\n",
    "from Evolution import Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import bisect\n",
    "\n",
    "class RLDataset(Dataset):\n",
    "    def __init__(self, data_1m: pd.DataFrame, data_1d: pd.DataFrame, feature_columns: list, close_time_list: list, index_list: list):\n",
    "        \"\"\"\n",
    "        초기화 메서드\n",
    "        \"\"\"\n",
    "        self.data_1m = data_1m\n",
    "        self.data_1d = data_1d\n",
    "        self.feature_columns = feature_columns\n",
    "        self.close_time_list = close_time_list\n",
    "        self.index_list = sorted(index_list)  # 정렬된 리스트로 가정\n",
    "        \n",
    "        # data_1m의 'Close time'을 numpy array로 변환하여 searchsorted 사용\n",
    "        self.data_1m_times = self.data_1m['Close time'].values\n",
    "        self.index_array = sorted(self.index_list)  # 이진 탐색을 위해 정렬\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        데이터셋의 전체 길이를 반환합니다.\n",
    "        \"\"\"\n",
    "        return len(self.close_time_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        주어진 인덱스에 해당하는 데이터를 반환합니다.\n",
    "        \"\"\"\n",
    "        # 1. close_time_list에서 해당 인덱스의 날짜를 가져옵니다.\n",
    "        current_date = self.close_time_list[idx]\n",
    "        \n",
    "        # 2. data_1d에서 현재 날짜를 포함한 60일 이전의 데이터를 가져옵니다.\n",
    "        start_date = current_date - pd.Timedelta(days=59)  # 현재 날짜 포함 60일\n",
    "        mask = (self.data_1d['Close time'] >= start_date) & (self.data_1d['Close time'] <= current_date)\n",
    "        data_60d = self.data_1d.loc[mask, self.feature_columns]\n",
    "        \n",
    "        # 데이터가 충분하지 않으면 예외 처리\n",
    "        if len(data_60d) < 60:\n",
    "            raise ValueError(f\"Not enough data for index {idx}: expected 60 days, got {len(data_60d)} days.\")\n",
    "        \n",
    "        # 피처를 텐서로 변환\n",
    "        features = torch.tensor(data_60d.values, dtype=torch.float32)\n",
    "        \n",
    "        # 3. 다음 날짜의 시작 인덱스를 data_1m에서 찾습니다.\n",
    "        next_date = current_date + pd.Timedelta(days=1)\n",
    "        \n",
    "        # 이진 탐색을 사용하여 next_date 이상의 첫 번째 위치 찾기\n",
    "        start_pos = bisect.bisect_left(self.data_1m_times, next_date)\n",
    "        if start_pos >= len(self.data_1m_times):\n",
    "            raise ValueError(f\"No data found in data_1m after {next_date}.\")\n",
    "        start_index = self.data_1m.index[start_pos]\n",
    "        \n",
    "        # 4. index_list에서 start_index보다 큰 첫 번째 값을 찾습니다.\n",
    "        # 이진 탐색을 사용하여 start_index보다 큰 첫 번째 값 찾기\n",
    "        greater_pos = bisect.bisect_right(self.index_array, start_index)\n",
    "        if greater_pos >= len(self.index_array):\n",
    "            raise ValueError(f\"No index in index_list greater than start_index {start_index}.\")\n",
    "        first_greater_index = self.index_array[greater_pos]\n",
    "        \n",
    "        # 5. 다음 날짜 + 30일의 날짜를 계산하고, 그 날짜의 마지막 인덱스를 찾습니다.\n",
    "        end_date = current_date + pd.Timedelta(days=31)  # 다음날 포함 30일\n",
    "        # 이진 탐색을 사용하여 end_date 이하의 마지막 위치 찾기\n",
    "        end_pos = bisect.bisect_right(self.data_1m_times, end_date) - 1\n",
    "        if end_pos < 0:\n",
    "            end_index = self.index_array[-1]\n",
    "        else:\n",
    "            end_index_candidate = self.data_1m.index[end_pos]\n",
    "            # index_list에서 end_index_candidate보다 작은 가장 큰 값 찾기\n",
    "            less_pos = bisect.bisect_left(self.index_array, end_index_candidate)\n",
    "            if less_pos == 0:\n",
    "                raise ValueError(f\"No index in index_list less than end_index_candidate {end_index_candidate}.\")\n",
    "            end_index = self.index_array[less_pos - 1]\n",
    "        \n",
    "        # 6. 추출한 데이터 프레임, 시작 index, end_index를 반환합니다.\n",
    "        return features, first_greater_index, end_index, greater_pos, less_pos - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3517693/3517693 [06:31<00:00, 8994.48it/s] \n"
     ]
    }
   ],
   "source": [
    "def data_setting():\n",
    "    # Load Data\n",
    "    data_1m = load_data_1m('/root/daily/bit/data/1min_bitusdt.pkl')\n",
    "    # data_1m = data_1m.iloc[:500000]\n",
    "\n",
    "    # Resample data to 1D\n",
    "    data_1d = resample_data(data_1m, '1D')\n",
    "    data_1d['Close time'] = data_1d.index\n",
    "    data_1d = data_1d.reset_index(drop=True)\n",
    "\n",
    "    # Apply Feature Calculations\n",
    "    # For 1D Data\n",
    "    data_1d, ma_cols_1d, ma_cols_rel_1d = calculate_MA_data(data_1d, 60, 'EMA', '_1d')\n",
    "    data_1d, bb_cols_1d, bb_cols_rel_1d = calculate_ema_bollinger_bands(data_1d, 60, extra_str='_1d')\n",
    "    data_1d, rsi_cols_1d = calculate_rsi(data_1d, window=20, extra_str='_1d')\n",
    "    data_1d, macd_cols_1d = calculate_macd(data_1d, 20, 120, 60, extra_str='_1d')\n",
    "    data_1d, stoch_cols_1d = calculate_stochastic_oscillator(data_1d, 60, 20, extra_str='_1d')\n",
    "    data_1d, adx_cols_1d = calculate_adx(data_1d, 60, extra_str='_1d')\n",
    "    data_1d, atr_cols_1d = calculate_atr(data_1d, 60, extra_str='_1d')\n",
    "    data_1d, obv_cols_1d = calculate_obv(data_1d, extra_str='_1d')\n",
    "    data_1d, will_cols_1d = calculate_williams_r(data_1d, 60, extra_str='_1d')\n",
    "    data_1d, base_feature_1d = base_feature_fn(data_1d, extra_str='_1d')\n",
    "    data_1d, cyclice_encoding_1d = cyclic_encode_fn(data_1d, 'Close time', 'day_of_year')\n",
    "\n",
    "    # For 1M Data\n",
    "    data_1m, ma_cols, ma_cols_rel = calculate_MA_data(data_1m, 240, 'EMA')\n",
    "    data_1m, bb_cols, bb_cols_rel = calculate_ema_bollinger_bands(data_1m, 240)\n",
    "    data_1m, rsi_cols = calculate_rsi(data_1m, window=60)\n",
    "    data_1m, macd_cols = calculate_macd(data_1m, 60, 600, 240)\n",
    "    data_1m, stoch_cols = calculate_stochastic_oscillator(data_1m, 240, 60)\n",
    "    data_1m, adx_cols = calculate_adx(data_1m, 240)\n",
    "    data_1m, atr_cols = calculate_atr(data_1m, 240)\n",
    "    data_1m, obv_cols = calculate_obv(data_1m)\n",
    "    data_1m, will_cols = calculate_williams_r(data_1m, 240)\n",
    "    data_1m, base_feature = base_feature_fn(data_1m)\n",
    "    data_1m, cyclice_encoding = cyclic_encode_fn(data_1m, 'Open time')\n",
    "\n",
    "    data_1m, short_ma_cols, short_ma_cols_rel = calculate_MA_data(data_1m, 60, 'EMA')\n",
    "    data_1m, long_ma_cols, long_ma_cols_rel = calculate_MA_data(data_1m, 180, 'EMA')\n",
    "\n",
    "    # Prepare Feature Columns\n",
    "    drop_column = [\n",
    "        'Open time', 'Close time', 'Quote asset volume', 'Ignore',\n",
    "        'Number of trades', 'Taker buy base asset volume', 'Taker buy quote asset volume'\n",
    "    ]\n",
    "    feature_column = (\n",
    "        ma_cols_rel + bb_cols_rel + rsi_cols + macd_cols + stoch_cols +\n",
    "        adx_cols + will_cols + base_feature + cyclice_encoding  # Excluding obv and atr\n",
    "    )\n",
    "    feature_column_1d = (\n",
    "        ma_cols_rel_1d + bb_cols_rel_1d + rsi_cols_1d + macd_cols_1d + stoch_cols_1d +\n",
    "        adx_cols_1d + will_cols_1d + base_feature_1d + cyclice_encoding_1d\n",
    "    )\n",
    "\n",
    "    # Apply Log Transform\n",
    "    for feature in feature_column:\n",
    "        data_1m[feature] = log_transform(data_1m[feature])\n",
    "\n",
    "    for feature in feature_column_1d:\n",
    "        data_1d[feature] = log_transform(data_1d[feature])\n",
    "\n",
    "    data_1d['%D_20__1d'] = 0\n",
    "    data_1d['ADX_60__1d'] = 0\n",
    "\n",
    "    # bb_entry_pos_list, patience_list, bb_entry_index_list = BB_fitness_fn(data_1m)\n",
    "    bb_macd_entry_pos_list, patience_list, bb_macd_entry_index_list = BB_MACD_fitness_fn(data_1m, 240, 60, 180)\n",
    "\n",
    "    # Prepare Dataset\n",
    "    data_tensor = make_dataset(\n",
    "        data_1m, data_1d,\n",
    "        using_column=feature_column, using_column_1d=feature_column_1d,\n",
    "        window_size=240, window_size_1d=60,\n",
    "        entry_pos_list=bb_macd_entry_pos_list, patience_list=patience_list,\n",
    "        use_1d_data=True\n",
    "    )\n",
    "    entry_pos_list = np.array(bb_macd_entry_pos_list)[np.array(bb_macd_entry_pos_list) != 'hold']\n",
    "\n",
    "    dataset_1m = []\n",
    "    dataset_1d = []\n",
    "    skip_data_cnt = 0\n",
    "    for data in data_tensor:\n",
    "        if len(data[0]) == 240 and len(data[1]) == 60:\n",
    "            dataset_1m.append(torch.from_numpy(data[0]).unsqueeze(dim=0))\n",
    "            dataset_1d.append(torch.from_numpy(data[1]).unsqueeze(dim=0))\n",
    "        else:\n",
    "            skip_data_cnt += 1\n",
    "    dataset_1m = torch.cat(dataset_1m, dim=0)\n",
    "    dataset_1d = torch.cat(dataset_1d, dim=0)\n",
    "    dataset_1m = replace_nan_with_zero(dataset_1m)\n",
    "    dataset_1d = replace_nan_with_zero(dataset_1d)\n",
    "\n",
    "    return (data_1m, data_1d, dataset_1m, dataset_1d, skip_data_cnt, \n",
    "            entry_pos_list, bb_macd_entry_index_list, feature_column, \n",
    "            feature_column_1d)\n",
    "\n",
    "\n",
    "data_1m, data_1d, dataset_1m, dataset_1d, skip_data_cnt, entry_pos_list, \\\n",
    "bb_macd_entry_index_list, feature_column, feature_column_1d = data_setting()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_time_list = data_1d['Close time'].tolist()[120:-30]\n",
    "# 전체 데이터 길이\n",
    "total_length = len(close_time_list)\n",
    "\n",
    "# train, valid, test 데이터 비율\n",
    "train_ratio = 0.6\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 각 데이터셋의 인덱스 계산\n",
    "train_end = int(total_length * train_ratio)\n",
    "valid_end = int(total_length * (train_ratio + valid_ratio))\n",
    "\n",
    "# 순서대로 데이터 분리\n",
    "train_close_time_list = close_time_list[:train_end]\n",
    "valid_close_time_list = close_time_list[train_end:valid_end]\n",
    "test_close_time_list = close_time_list[valid_end:]\n",
    "\n",
    "# 각 데이터셋 생성\n",
    "train_dataset = RLDataset(data_1m, data_1d, feature_column_1d, train_close_time_list, bb_macd_entry_index_list)\n",
    "valid_dataset = RLDataset(data_1m, data_1d, feature_column_1d, valid_close_time_list, bb_macd_entry_index_list)\n",
    "test_dataset = RLDataset(data_1m, data_1d, feature_column_1d, test_close_time_list, bb_macd_entry_index_list)\n",
    "\n",
    "# DataLoader 생성 (순서 유지 위해 shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_model(best_index=None):\n",
    "    # torch.set_grad_enabled(False)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    state_dict_path = '/root/daily/bit/generation_t/generation_t.pt'\n",
    "    if os.path.exists(state_dict_path):\n",
    "        state_dict = torch.load(state_dict_path)\n",
    "        start_gen = state_dict['generation'] + 1\n",
    "        best_profit = state_dict['best_profit']\n",
    "        best_chromosomes = state_dict['best_chromosomes']\n",
    "\n",
    "    if best_index is None:\n",
    "        best_index = [i for i in range(len(best_profit))]\n",
    "\n",
    "    chromosomes_size = len(best_index)\n",
    "\n",
    "    # Evolution Setup\n",
    "    device = 'cuda:1'\n",
    "    group = len(best_index)\n",
    "    prescriptor = Prescriptor(\n",
    "        basic_block=None, \n",
    "        base_small_input_dim=20, \n",
    "        base_large_input_dim=20,\n",
    "        base_hidden_dim=32, \n",
    "        base_output_dim=16, \n",
    "        after_input_dim=19, \n",
    "        after_hidden_dim=32, \n",
    "        after_output_dim=6, \n",
    "        num_blocks=len(best_index),\n",
    "    ).to(device)\n",
    "\n",
    "    total_param = sum(p.numel() for p in prescriptor.parameters())\n",
    "    print(f\"Total parameters: {total_param}\")\n",
    "\n",
    "    selection = RouletteSelection(elite_num=2000, parents_num=4000, minimize=False)\n",
    "    crossover = DifferentialEvolutionOperator()\n",
    "    mutation = RandomValueMutation(mut_prob=0.05)\n",
    "    evolution = Evolution(\n",
    "        prescriptor=prescriptor,\n",
    "        selection=selection,\n",
    "        crossover=crossover,\n",
    "        mutation=mutation\n",
    "    )\n",
    "\n",
    "    best_chromosomes = best_chromosomes[best_index]\n",
    "    init_chromosomes, base_ch_shape, after_ch_shape, device = evolution.flatten_chromosomes()\n",
    "    device = 'cuda:1'\n",
    "    evolution.update_chromosomes(best_chromosomes, base_ch_shape, after_ch_shape, device)\n",
    "\n",
    "    return evolution, prescriptor, chromosomes_size, device\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, data_1d):\n",
    "        self.data = data\n",
    "        self.data_1d = data_1d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data_1d[idx]\n",
    "\n",
    "def evo_inference(dataset_1m, dataset_1d, prescriptor, device):\n",
    "    def inference(scaled_tensor, scaled_tensor_1d, model, device='cuda:0'):\n",
    "        dataset = CustomDataset(scaled_tensor, scaled_tensor_1d)\n",
    "        dataloader = DataLoader(dataset, batch_size=2048, shuffle=False, num_workers=8, pin_memory=True)\n",
    "        logits = []\n",
    "        for data, data_1d in dataloader:\n",
    "            data = data.to(torch.float32).to(device)\n",
    "            data_1d = data_1d.to(torch.float32).to(device)\n",
    "            logit = model.base_forward(data, data_1d)\n",
    "            logits.append(logit)\n",
    "        return logits\n",
    "    probs = inference(dataset_1m, dataset_1d, prescriptor, device)\n",
    "    probs = torch.concat(probs, dim=1)\n",
    "    probs = probs.squeeze(dim=2)\n",
    "\n",
    "    return probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1110712\n"
     ]
    }
   ],
   "source": [
    "best_index = [  5,   7,  13,  15,  16,  19,  24,  30,  45,  50,  56,  68,  69,\n",
    "        74,  79,  80,  83, 105, 112, 115, 119, 128, 133, 139, 140, 153,\n",
    "       157, 159, 163, 177, 181, 187, 193, 198]\n",
    "evolution, prescriptor, chromosomes_size, device = setting_model(best_index)\n",
    "rl_model = ChromosomeSelectorModel(20, 256, chromosomes_size, 4).to(device)\n",
    "with torch.no_grad():\n",
    "    probs = evo_inference(dataset_1m, dataset_1d, prescriptor, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import copy  # Best model 저장을 위해 사용\n",
    "import os\n",
    "\n",
    "def train_rl(\n",
    "    rl_model,              # ChromosomeSelectorModel\n",
    "    dataloader_rl_train,  # 학습용 DataLoader\n",
    "    dataloader_rl_valid,  # 검증용 DataLoader\n",
    "    dataloader_rl_test,   # 테스트용 DataLoader\n",
    "    prescriptor,          # Prescriptor loaded with GA-evolved chromosomes\n",
    "    data_1m, \n",
    "    probs, \n",
    "    entry_index_list, \n",
    "    entry_pos_list, \n",
    "    skip_data_cnt, \n",
    "    chromosomes_size, \n",
    "    device,\n",
    "    num_epochs=10,\n",
    "    lr=1e-4,\n",
    "    alpha=1,\n",
    "    cut_percent=90,\n",
    "    limit=4,\n",
    "    accumulation_steps=32,\n",
    "    save_path='/root/daily/bit/rl_/best_rl_model.pth',  # 최적 모델 저장 경로\n",
    "    early_stopping_patience=5       # 조기 종료를 위한 patience\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the RL model to assign weights to each GA chromosome, including validation and testing.\n",
    "\n",
    "    Args:\n",
    "        rl_model (nn.Module): The RL model that outputs logits for each chromosome.\n",
    "        dataloader_rl_train (DataLoader): DataLoader for training dataset.\n",
    "        dataloader_rl_valid (DataLoader): DataLoader for validation dataset.\n",
    "        dataloader_rl_test (DataLoader): DataLoader for test dataset.\n",
    "        prescriptor (nn.Module): The Prescriptor, which is your GA-based model with multiple chromosomes.\n",
    "        data_1m (pd.DataFrame): The original 1-minute DataFrame.\n",
    "        probs (torch.Tensor): Output of `evo_inference(...)`, shape ~ (chromosomes_size, N) or similar.\n",
    "        entry_index_list, entry_pos_list, skip_data_cnt: Inputs for your fitness_fn.\n",
    "        chromosomes_size (int): Number of chromosomes.\n",
    "        device (str): 'cuda:0' or 'cpu'.\n",
    "        num_epochs (int): How many epochs to train for.\n",
    "        lr (float): Learning rate for the optimizer.\n",
    "        alpha (float): Parameter passed to fitness_fn.\n",
    "        cut_percent (float): Parameter passed to fitness_fn.\n",
    "        limit (int): Parameter passed to fitness_fn.\n",
    "        accumulation_steps (int): Number of steps to accumulate gradients.\n",
    "        save_path (str): Path to save the best model.\n",
    "        early_stopping_patience (int): Number of epochs with no improvement after which training will be stopped.\n",
    "\n",
    "    Returns:\n",
    "        rl_model (nn.Module): The updated RL model after training.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure the RL model is on the correct device\n",
    "    rl_model.to(device)\n",
    "\n",
    "    # Ensure all model parameters require gradients\n",
    "    for param in rl_model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Create an optimizer for the RL model\n",
    "    optimizer = Adam(rl_model.parameters(), lr=lr)\n",
    "\n",
    "    # Set the model to training mode\n",
    "    rl_model.train()\n",
    "\n",
    "    best_valid_profit = -float('inf')\n",
    "    best_model_state = copy.deepcopy(rl_model.state_dict())\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        rl_model.train()\n",
    "        total_loss = 0.0\n",
    "        total_profit = 0.0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for idx, data in enumerate(dataloader_rl_train):\n",
    "            try:\n",
    "                # Retrieve data from the dataset\n",
    "                features_1d, first_greater_index, end_index, greater_pos, less_pos = data\n",
    "            except ValueError as e:\n",
    "                # Skip if data is insufficient\n",
    "                continue\n",
    "\n",
    "            # Move features to device and add batch dimension\n",
    "            features_1d = features_1d.to(device)  # Shape: [1, num_features]\n",
    "\n",
    "            # Forward pass through RL model to get logits\n",
    "            logits = rl_model(features_1d)  # Shape: [1, chromosomes_size]\n",
    "\n",
    "            # Convert logits to weights via softmax\n",
    "            weights = F.softmax(logits, dim=-1)  # Shape: [1, chromosomes_size]\n",
    "\n",
    "            # Optional: Zero out weights below a threshold and renormalize\n",
    "            mask = weights >= 0.1\n",
    "            if mask.sum() < 1:\n",
    "                # If all weights are below 0.1, keep as is\n",
    "                pass\n",
    "            else:\n",
    "                weights = weights * mask.float()\n",
    "                weights = weights / weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "            # Compute the monthly reward (fitness) for each chromosome without tracking gradients\n",
    "            with torch.no_grad():\n",
    "                train_metrics = fitness_fn(\n",
    "                    prescriptor=prescriptor,\n",
    "                    data=data_1m,\n",
    "                    probs=probs,\n",
    "                    entry_index_list=entry_index_list,\n",
    "                    entry_pos_list=entry_pos_list,\n",
    "                    skip_data_cnt=skip_data_cnt,\n",
    "                    start_data_cnt=greater_pos,\n",
    "                    chromosomes_size=chromosomes_size,\n",
    "                    window_size=240,\n",
    "                    alpha=alpha,\n",
    "                    cut_percent=cut_percent,\n",
    "                    device=device,\n",
    "                    stop_cnt=less_pos,\n",
    "                    profit_init=1,\n",
    "                    limit=limit\n",
    "                )\n",
    "\n",
    "                # Convert train_metrics to tensor and extract profits\n",
    "                # Assuming train_metrics is a list or numpy array\n",
    "                monthly_profits = torch.tensor(train_metrics, dtype=torch.float32, device=device)[:, 6]  # Shape: [chromosomes_size]\n",
    "\n",
    "            # Compute baseline profit\n",
    "            baseline_profit = monthly_profits.mean()\n",
    "\n",
    "            # Compute portfolio profit as weighted sum of monthly profits\n",
    "            # weights is [1, chromosomes_size], monthly_profits is [chromosomes_size]\n",
    "            portfolio_profit = (weights.squeeze(0) * monthly_profits).mean()\n",
    "\n",
    "            # Optionally subtract baseline to center the reward\n",
    "            portfolio_profit = portfolio_profit - baseline_profit\n",
    "\n",
    "            # Compute loss (negative of portfolio profit to maximize profit)\n",
    "            loss = -portfolio_profit\n",
    "\n",
    "            # Backpropagate loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Accumulate loss and profit for logging\n",
    "            total_loss += loss.item()\n",
    "            total_profit += portfolio_profit.item()\n",
    "\n",
    "            # Gradient accumulation\n",
    "            if (idx + 1) % accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        # Perform a final optimizer step if there are remaining gradients\n",
    "        if (len(dataloader_rl_train) % accumulation_steps) != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Compute average loss and profit for the training epoch\n",
    "        avg_train_loss = total_loss / max(1, len(dataloader_rl_train))\n",
    "        avg_train_profit = total_profit / max(1, len(dataloader_rl_train))\n",
    "\n",
    "        # Validation Phase\n",
    "        rl_model.eval()\n",
    "        total_valid_profit = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(dataloader_rl_valid):\n",
    "                try:\n",
    "                    features_1d, first_greater_index, end_index, greater_pos, less_pos = data\n",
    "                except ValueError as e:\n",
    "                    continue\n",
    "\n",
    "                features_1d = features_1d.to(device)\n",
    "\n",
    "                logits = rl_model(features_1d)\n",
    "                weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "                mask = weights >= 0.1\n",
    "                if mask.sum() < 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    weights = weights * mask.float()\n",
    "                    weights = weights / weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "                train_metrics = fitness_fn(\n",
    "                    prescriptor=prescriptor,\n",
    "                    data=data_1m,\n",
    "                    probs=probs,\n",
    "                    entry_index_list=entry_index_list,\n",
    "                    entry_pos_list=entry_pos_list,\n",
    "                    skip_data_cnt=skip_data_cnt,\n",
    "                    start_data_cnt=greater_pos,\n",
    "                    chromosomes_size=chromosomes_size,\n",
    "                    window_size=240,\n",
    "                    alpha=alpha,\n",
    "                    cut_percent=cut_percent,\n",
    "                    device=device,\n",
    "                    stop_cnt=less_pos,\n",
    "                    profit_init=1,\n",
    "                    limit=limit\n",
    "                )\n",
    "\n",
    "                monthly_profits = torch.tensor(train_metrics, dtype=torch.float32, device=device)[:, 6]\n",
    "                baseline_profit = monthly_profits.mean()\n",
    "                portfolio_profit = (weights.squeeze(0) * monthly_profits).mean()\n",
    "                portfolio_profit = portfolio_profit - baseline_profit\n",
    "\n",
    "                total_valid_profit += portfolio_profit.item()\n",
    "\n",
    "        avg_valid_profit = total_valid_profit / max(1, len(dataloader_rl_valid))\n",
    "\n",
    "        # Check for improvement\n",
    "        if avg_valid_profit > best_valid_profit:\n",
    "            best_valid_profit = avg_valid_profit\n",
    "            best_model_state = copy.deepcopy(rl_model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model\n",
    "            torch.save(best_model_state, save_path)\n",
    "            print(f\"-> New best model saved with Validation Profit: {best_valid_profit:.6f}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"-> No improvement in validation profit for {epochs_no_improve} epoch(s)\")\n",
    "\n",
    "        # Early Stopping\n",
    "        if epochs_no_improve >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "        # Logging\n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {avg_train_loss:.6f}, \"\n",
    "              f\"Train Profit: {avg_train_profit:.6f}, \"\n",
    "              f\"Validation Profit: {avg_valid_profit:.6f}\")\n",
    "\n",
    "    # Load the best model state\n",
    "    rl_model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Testing Phase\n",
    "    rl_model.eval()\n",
    "    total_test_profit = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(dataloader_rl_test):\n",
    "            try:\n",
    "                features_1d, first_greater_index, end_index, greater_pos, less_pos = data\n",
    "            except ValueError as e:\n",
    "                continue\n",
    "\n",
    "            features_1d = features_1d.to(device)\n",
    "\n",
    "            logits = rl_model(features_1d)\n",
    "            weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "            mask = weights >= 0.1\n",
    "            if mask.sum() < 1:\n",
    "                pass\n",
    "            else:\n",
    "                weights = weights * mask.float()\n",
    "                weights = weights / weights.sum(dim=-1, keepdim=True)\n",
    "\n",
    "            train_metrics = fitness_fn(\n",
    "                prescriptor=prescriptor,\n",
    "                data=data_1m,\n",
    "                probs=probs,\n",
    "                entry_index_list=entry_index_list,\n",
    "                entry_pos_list=entry_pos_list,\n",
    "                skip_data_cnt=skip_data_cnt,\n",
    "                start_data_cnt=greater_pos,\n",
    "                chromosomes_size=chromosomes_size,\n",
    "                window_size=240,\n",
    "                alpha=alpha,\n",
    "                cut_percent=cut_percent,\n",
    "                device=device,\n",
    "                stop_cnt=less_pos,\n",
    "                profit_init=1,\n",
    "                limit=limit\n",
    "            )\n",
    "\n",
    "            monthly_profits = torch.tensor(train_metrics, dtype=torch.float32, device=device)[:, 6]\n",
    "            baseline_profit = monthly_profits.mean()\n",
    "            portfolio_profit = (weights.squeeze(0) * monthly_profits).mean()\n",
    "            portfolio_profit = portfolio_profit - baseline_profit\n",
    "\n",
    "            total_test_profit += portfolio_profit.item()\n",
    "\n",
    "    avg_test_profit = total_test_profit / max(1, len(dataloader_rl_test))\n",
    "    print(f\"Test Profit: {avg_test_profit:.6f}\")\n",
    "\n",
    "    return rl_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> New best model saved with Validation Profit: -0.903930\n",
      "[Epoch 1/10] Train Loss: 0.916015, Train Profit: -0.916015, Validation Profit: -0.903930\n",
      "-> New best model saved with Validation Profit: -0.903836\n",
      "[Epoch 2/10] Train Loss: 0.915059, Train Profit: -0.915059, Validation Profit: -0.903836\n",
      "-> New best model saved with Validation Profit: -0.903836\n",
      "[Epoch 3/10] Train Loss: 0.915007, Train Profit: -0.915007, Validation Profit: -0.903836\n"
     ]
    }
   ],
   "source": [
    "rl_model = train_rl(rl_model,              # ChromosomeSelectorModel\n",
    "                    train_dataloader,\n",
    "                    valid_dataloader,\n",
    "                    test_dataloader,# RLDataset\n",
    "                    prescriptor,           # Prescriptor loaded with GA-evolved chromosomes\n",
    "                    data_1m, \n",
    "                    probs, \n",
    "                    bb_macd_entry_index_list, \n",
    "                    entry_pos_list, \n",
    "                    skip_data_cnt, \n",
    "                    chromosomes_size, \n",
    "                    device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
